{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNlcwxKR9gXt"
      },
      "source": [
        "### Install some dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0wlrXoS1EP-"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U accelerate==0.27.1\n",
        "!pip install -q -U datasets==2.17.0\n",
        "!pip install -q -U transformers==4.38.1\n",
        "!pip install langchain sentence-transformers chromadb langchainhub\n",
        "!pip install llama-cpp-python\n",
        "!pip install langchain-community langchain-core\n",
        "!pip install evaluate\n",
        "!pip install bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"huggingface_hub\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymTffeGN4EH-"
      },
      "outputs": [],
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "# define text-generation model\n",
        "model_path = \"mistral-7b-instruct-v0.2.Q4_0.gguf\"\n",
        "model = Llama(model_path=model_path, n_ctx=2048, n_threads=8, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGq9g41dv3ru"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import chromadb\n",
        "\n",
        "# define embedding model\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "client = chromadb.PersistentClient(path=\"./chroma_db\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVLl-QTT61Aw",
        "outputId": "22d88b44-33d8-4f08-c0d1-2d480c1944ba"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import concurrent.futures\n",
        "import uuid\n",
        "import os\n",
        "\n",
        "# define the list of files to process\n",
        "file_names = [\n",
        "    \"study_permit_general\", \"work_permit_student_general\", \"work-study-data-llm\",\n",
        "    \"vancouver_transit_qa_pairs\", \"permanent_residence_student_general\", \"data-with-sources\",\n",
        "    \"faq_qa_pairs_general\", \"hikes_qa\", \"sfu-faq-with-sources\", \"sfu-housing-with-sources\",\n",
        "    \"sfu-immigration-faq\", \"park_qa_pairs-up\", \"cultural_space_qa_pairs_up\",\n",
        "    \"qa_pairs_food\", \"qa_pairs_year_and_month_avg\", \"qa_pairs_sfu_clubs\"\n",
        "]\n",
        "\n",
        "collections = {}\n",
        "batch_size = 32\n",
        "\n",
        "def process_file(file):\n",
        "    try:\n",
        "        path = f'../Data/{file}.csv'\n",
        "        if not os.path.exists(path):\n",
        "            return f\"{file} skipped (file not found).\"\n",
        "\n",
        "        df = pd.read_csv(path, usecols=lambda col: col.lower() in {\"question\", \"answer\"})\n",
        "        df.columns = df.columns.str.lower()\n",
        "\n",
        "        if \"question\" not in df.columns or \"answer\" not in df.columns:\n",
        "            return f\"{file} skipped (missing question/answer columns).\"\n",
        "\n",
        "        df = df.drop_duplicates(subset=\"question\")\n",
        "        df[\"text\"] = df[\"question\"].fillna('') + ' ' + df[\"answer\"].fillna('')\n",
        "        unique_texts = list(set(df[\"text\"].dropna().tolist()))\n",
        "\n",
        "        collection = client.get_or_create_collection(name=file)\n",
        "        for i in range(0, len(unique_texts), batch_size):\n",
        "            batch = unique_texts[i:i + batch_size]\n",
        "            embeddings = embedding_model.embed_documents(batch)\n",
        "            ids = [str(uuid.uuid4()) for _ in batch]\n",
        "            collection.add(ids=ids, embeddings=embeddings, documents=batch)\n",
        "\n",
        "        collections[file] = collection\n",
        "        return f\"{file}: Loaded {len(unique_texts)} docs.\"\n",
        "    except Exception as e:\n",
        "        return f\"{file}: Error - {e}\"\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
        "    results = list(executor.map(process_file, file_names))\n",
        "\n",
        "for result in results:\n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r976Yrgqdvjk"
      },
      "outputs": [],
      "source": [
        "collection_map = {\n",
        "    \"study_permit\": \"study_permit_general\",\n",
        "    \"work_permit\": \"work_permit_student_general\",\n",
        "    \"work_study\": \"work-study-data-llm\",\n",
        "    \"public_transit\": \"vancouver_transit_qa_pairs\",\n",
        "    \"permanent_residence\": \"permanent_residence_student_general\",\n",
        "    \"health_related\": \"data-with-sources\",\n",
        "    \"general_faqs\": \"faq_qa_pairs_general\",\n",
        "    \"vancouver_hiking\": \"hikes_qa\",\n",
        "    \"university_general_faqs\": \"sfu-faq-with-sources\",\n",
        "    \"university_housing\": \"sfu-housing-with-sources\",\n",
        "    \"university_immigration_faqs\": \"sfu-immigration-faq\",\n",
        "    \"vancouver_parks\": \"park_qa_pairs-up\",\n",
        "    \"vancouver_cultural\": \"cultural_space_qa_pairs_up\",\n",
        "    \"university_food\": \"qa_pairs_food\",\n",
        "    \"expenditure\": \"qa_pairs_year_and_month_avg\",\n",
        "    \"university_clubs\": \"qa_pairs_sfu_clubs\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEulNQZw8mDo"
      },
      "outputs": [],
      "source": [
        "def get_relevant_documents(query, categories, n_results=3):\n",
        "    all_results = []\n",
        "    query_embedding = embedding_model.embed_documents([query])[0]\n",
        "    for category in categories:\n",
        "        collection_name = collection_map[category]\n",
        "        if collection_name in collections:\n",
        "            try:\n",
        "                result = collections[collection_name].query(\n",
        "                    query_embeddings=[query_embedding],\n",
        "                    n_results=n_results\n",
        "                )\n",
        "                docs = result.get(\"documents\", [[]])[0]\n",
        "                sims = result.get(\"distances\", [[]])[0]\n",
        "            \n",
        "                category_results = [(f\"{doc} [Source: {collection_name}]\", sim) for doc, sim in zip(docs, sims)]\n",
        "                all_results.extend(zip(docs, sims))\n",
        "            except Exception as e:\n",
        "                print(f\"error querying {collection_name}: {e}\")\n",
        "\n",
        "    all_results = sorted(all_results, key=lambda x: x[1])\n",
        "\n",
        "    # return top results but ensure we get at least one from each category when possible\n",
        "    if len(categories) > 1 and len(all_results) > n_results:\n",
        "        # try to get at least one result from each category\n",
        "        diverse_results = []\n",
        "        seen_categories = set()\n",
        "        \n",
        "        for doc, sim in all_results:\n",
        "            doc_category = next((cat for cat in categories if collection_map.get(cat) in doc), None)\n",
        "            if doc_category and doc_category not in seen_categories:\n",
        "                diverse_results.append((doc, sim))\n",
        "                seen_categories.add(doc_category)\n",
        "                \n",
        "                if len(diverse_results) >= min(n_results, len(categories)):\n",
        "                    break\n",
        "        \n",
        "        # then fill remaining slots with best results\n",
        "        remaining_slots = n_results - len(diverse_results)\n",
        "        if remaining_slots > 0:\n",
        "            for doc, sim in all_results:\n",
        "                if (doc, sim) not in diverse_results:\n",
        "                    diverse_results.append((doc, sim))\n",
        "                    if len(diverse_results) >= n_results:\n",
        "                        break\n",
        "        \n",
        "        return diverse_results\n",
        "    else:\n",
        "        return all_results[:n_results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVTQznmhfN9V"
      },
      "outputs": [],
      "source": [
        "import difflib\n",
        "\n",
        "valid_categories = list(collection_map.keys())\n",
        "fallback_category = \"general_faqs\"\n",
        "\n",
        "def classify_query(query):\n",
        "    category_prompt = f\"\"\"\n",
        "    You are a classifier for a Q&A system for international students in British Columbia.\n",
        "    Pick ONLY from this list of category names (copy them exactly, case-insensitive), and return up to 3 relevant ones (comma-separated):\n",
        "\n",
        "    {\", \".join(valid_categories)}\n",
        "\n",
        "    Query: \"{query}\"\n",
        "\n",
        "    Return only the category name(s) as a comma-separated string.\n",
        "    \"\"\"\n",
        "\n",
        "    response = model(category_prompt, max_tokens=50, temperature=0.1)[\"choices\"][0][\"text\"].strip().lower()\n",
        "    print(f\"Raw classification output: {response}\")\n",
        "    \n",
        "    matched = []\n",
        "    \n",
        "    tokens = [t.strip() for t in response.split(\",\")]\n",
        "    \n",
        "    for token in tokens:\n",
        "        # check for exact matches first\n",
        "        if token in valid_categories and token not in matched:\n",
        "            matched.append(token)\n",
        "            continue\n",
        "            \n",
        "        # check for fuzzy matches if needed\n",
        "        closest = difflib.get_close_matches(token, valid_categories, n=1, cutoff=0.7)\n",
        "        if closest and closest[0] not in matched:\n",
        "            matched.append(closest[0])\n",
        "            \n",
        "        if len(matched) == 3:\n",
        "            break\n",
        "    \n",
        "    # if no matches found through simple splitting, try more aggressive pattern matching\n",
        "    if not matched:\n",
        "        for category in valid_categories:\n",
        "            if category in response and category not in matched:\n",
        "                matched.append(category)\n",
        "                if len(matched) == 3:\n",
        "                    break\n",
        "    \n",
        "    # always include fallback category if no matches found\n",
        "    if not matched:\n",
        "        matched = [fallback_category]\n",
        "    elif fallback_category not in matched and len(matched) < 3:\n",
        "        matched.append(fallback_category)\n",
        "        \n",
        "    print(f\"Classified categories: {matched}\")\n",
        "    return matched[:3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMTYliNl8onj"
      },
      "outputs": [],
      "source": [
        "def generate_answer(query):\n",
        "    categories = classify_query(query)\n",
        "    print(f\"Categories {categories}\\n\")\n",
        "    relevant_documents = get_relevant_documents(query, categories)\n",
        "\n",
        "    if not relevant_documents:\n",
        "        return {\n",
        "            \"Response\": \"Sorry, no relevant documents found.\"\n",
        "        }\n",
        "\n",
        "    seen = set()\n",
        "    unique_docs = []\n",
        "    for doc, sim in relevant_documents:\n",
        "        doc_text = doc.split(\" [Source: \")[0] if \" [Source: \" in doc else doc\n",
        "        if doc_text not in seen:\n",
        "            seen.add(doc_text)\n",
        "            unique_docs.append((doc, sim))\n",
        "\n",
        "    print(\"Relevant Documents with Similarity Scores:\")\n",
        "    for doc, sim in unique_docs:\n",
        "        print(f\"Similarity: {sim:.4f}\\nDoc: {doc}\\n\")\n",
        "\n",
        "    relevant_texts = \"\\n\\n\".join([doc.split(\" [Source: \")[0] for doc, _ in unique_docs])\n",
        "    \n",
        "    # category-wise prompts\n",
        "    hike_prompt = f\"\"\"\n",
        "        INSTRUCTIONS:\n",
        "            1. Convert structured information about the hike into a short, friendly paragraph using natural language. Do not repeat numbers or use formatting from the source.\n",
        "            2. If they ask about hiking information, only answer with required information. Users can ask for more information if needed.\n",
        "            3. When asked for a particular type of hike, find it instead of saying that one would not work in the category they asked for.\n",
        "            4. Do NOT list trail attributes or stats (like “Distance: 3.1 km, Elevation: 789 m”). Instead, describe them in context (e.g., “a steep 3 km trail with a tough 789 m climb”).\n",
        "            5. Avoid repeating exact numbers unless essential (e.g., elevation gain is helpful, but don't dump all stats).\n",
        "    \"\"\"\n",
        "    \n",
        "    parks_prompt = f\"\"\" \n",
        "        INSTRUCTIONS:\n",
        "            1. Convert structured information about the park into a short, friendly paragraph using natural language. Do not repeat numbers or use formatting from the source.\n",
        "            2. Provide only necessary information that will allow the user to enjoy the park.\n",
        "                - Feel free to tell them about logisitical information if asked.\n",
        "    \"\"\"\n",
        "    \n",
        "    food_prompt = f\"\"\" \n",
        "        INSTRUCTIONS:\n",
        "            1. Convert structured food and dining information into a friendly, helpful paragraph. Do not copy the question or use list formatting.\n",
        "            2. Only answer what the user asked. Do NOT add information that wasn't requested.\n",
        "            3. Describe details in a natural way (e.g., “open 24/7 during the semester” instead of “Hours: 24/7”).\n",
        "            4. Mention unique features only when they help clarify the user's question.\n",
        "            5. If a specific venue or program is asked about (e.g., a café, meal plan, or food station), describe it clearly in context.\n",
        "            6. If the question can't be answered from the data, respond with: “I'm sorry, I don't have that information. Please check the official SFU Food website.”\n",
        "            7. Provide the official link when available and relevant to the answer.\n",
        "            8. Do NOT list menu items, prices, or square footage unless directly relevant to the user's question.\n",
        "            9. Only provide food information that is relevant. If they ask for some place that serves a chicken sandwich do not provide information to a vegan place.\n",
        "    \"\"\"\n",
        "\n",
        "    # activities general: covers how to answer general parks, hikes, food, clubs, cultural related questions \n",
        "    activities_general = f\"\"\" \n",
        "        INSTRUCTIONS:\n",
        "            1. If they ask for suggestions, provide 2 to 3 suggestions.\n",
        "            2. Do NOT list all information. Instead describe them in context \n",
        "            3. Provide accuracte suggestions, NOT suggestions of things that will not work for what they want.\n",
        "            4. Convert structured information about the activity into a short, friendly paragraph using natural language. Do not repeat formatting from the source.\n",
        "    \"\"\"\n",
        "    \n",
        "    # permits prompt: covers ways to answer immigration, study permits, work permits, and permanent residence related questions \n",
        "    permits_prompt = f\"\"\"\n",
        "        INSTRUCTIONS:\n",
        "            1. When given a specific question with many possible answers, you can ask for more specific information.\n",
        "                - if they are not asking for an extension do not provide information in regards to an extension of a permit.\n",
        "            2. Only answer with information provided \n",
        "                - Information should NOT be guessed and do NOT add extra information\n",
        "            3. If the answer is not in the dataset, respond with: \"I'm sorry, I don't have that information. Please check the official IRCC website for more details.\"\n",
        "            4. If it is helpful, provide the link and a description about it.\n",
        "            5. Do NOT list all information. Instead describe them in context \n",
        "            6. If the answer depends on a specific condition explain those clearly.\n",
        "            7. Do NOT make assumptions about the user's situation. \n",
        "    \"\"\"\n",
        "    \n",
        "    housing_prompt = f\"\"\" \n",
        "        INSTRUCTIONS:\n",
        "            1. Convert structured information about SFU or general student housing into a short, friendly paragraph using natural language. Do not repeat formatting or list prices unless helpful for context.\n",
        "            2. Focus on what matters to the student: location, room types, meal plans, how to apply, and support available.\n",
        "            3. Only mention costs in a general way (e.g., \"starts around $4,000 per term\") unless the user explicitly asks for detailed pricing.\n",
        "            4. If information varies (e.g., by room type or campus), explain this clearly but briefly.\n",
        "            5. If the user asks a specific housing question and the answer depends on certain conditions (e.g., term length, student status), explain those conditions clearly and simply.\n",
        "            6. If the answer is not known or not in the data, respond with: \"I’m sorry, I don’t have that information. Please check the SFU Housing website for details.\"\n",
        "            7. Do NOT dump full lists of buildings, prices, or amenities. Summarize and keep it conversational.\n",
        "            8. If the information is specific to SFU, make sure you say it to be clear.\n",
        "    \"\"\"\n",
        "    \n",
        "    transit_prompt = f\"\"\" \n",
        "        INSTRUCTIONS:\n",
        "            1. Convert structured information about public transit into a short, friendly paragraph using natural language.\n",
        "            2. Do NOT list statistics or technical formatting (like route numbers or fare charts) unless directly relevant to the user's question.\n",
        "            3. Summarize relevant transit options clearly — describe them in context (e.g., “a quick SkyTrain ride from downtown to the airport”).\n",
        "            4. Provide only what the user needs to understand how to get around or plan their trip.\n",
        "            5. If the user is asking for directions, give a general summary of how they might travel.\n",
        "            6. If the question is about fares, schedules, or route planning and the exact info is not available, tell the user to check the TransLink website and briefly explain what they can find there.\n",
        "            7. Do NOT guess or make up transit information.\n",
        "            8. If the information is not in the source, say “I’m sorry, I don’t have that information. You can check the official TransLink site for more details.”\n",
        "    \"\"\"\n",
        "    \n",
        "    # main rag prompt\n",
        "    rag_prompt = f\"\"\"\n",
        "    You are a helpful, friendly assistant for international students new to British Columbia, Canada.\n",
        "\n",
        "    Below are some reference documents that may be relevant to the user's question:\n",
        "    {relevant_texts}\n",
        "\n",
        "    INSTRUCTIONS:\n",
        "    1. If the user's query is just a greeting (like \"hello\", \"hi\", \"what's up\"):\n",
        "       - Respond with a single brief friendly greeting\n",
        "       - Offer to help with questions about studying or living in BC\n",
        "       - Do NOT include ANY information from the reference documents\n",
        "       - Do NOT create additional answers beyond answering their original question\n",
        "\n",
        "    2. If the user is asking for information:\n",
        "       - Be friendly and answer based ONLY on the reference documents if relevant\n",
        "       - Summarize the necessary information into a couple sentences.\n",
        "       - Do NOT create additional questions and answers beyond answering their original question\n",
        "       - Limit your entire response to no more than 3 concise sentences when possible. Do not create long multi-line answers.\n",
        "       - If the documents don't provide sufficient information, say \"I don't have enough information to answer that. Please refer to official sources.\"\n",
        "       - Ask for more information when there are multiple scenarios in the documents.\n",
        "       - If they ask things like \"can I\", \"will I\", \"how can I\" feel free to ask follow up questions if you don't how to answer with the information provided. Do not just assume.\n",
        "    \n",
        "    3. IMPORTANT: Never generate additional content beyond answering the user's question. Do NOT number or bullet your points. Always use natural sentences and group similar information together where possible.\n",
        "    \n",
        "    User question: {query}\n",
        "\n",
        "    Your response (just the answer, no preamble):\n",
        "    \"\"\"\n",
        "    \n",
        "    # adding the category specific prompting to main if necessary\n",
        "    for category in categories:\n",
        "        if category == \"hiking\" or category == \"parks\" or category == \"food\" or category == \"cultural\" or category == \"clubs\":\n",
        "            rag_prompt += \"\\n\" + activities_general\n",
        "        if category == \"hiking\":\n",
        "            rag_prompt += \"\\n\" + hike_prompt\n",
        "        if category == \"parks\":\n",
        "            rag_prompt += \"\\n\" + parks_prompt\n",
        "        if category == \"food\":\n",
        "            rag_prompt += \"\\n\" + food_prompt\n",
        "        if category == \"study permit\" or category == \"work permit\" or category == \"immigration\" or category == \"permanent residence\":\n",
        "            rag_prompt += \"\\n\" + permits_prompt\n",
        "        if category == \"housing\":\n",
        "            rag_prompt += \"\\n\" + housing_prompt\n",
        "        if category == \"transit\":\n",
        "            rag_prompt += \"\\n\" + transit_prompt\n",
        "       \n",
        "    response_after_rag = model(rag_prompt, max_tokens=300, temperature=0.1)[\"choices\"][0][\"text\"]\n",
        "\n",
        "    return {\n",
        "        \"Response\": response_after_rag\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage\n",
        "answer = generate_answer(\"Are there any resources available from SFU to search for off campus accomodation?\")\n",
        "print(answer[\"Response\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EVDilNoM8sU8",
        "outputId": "20b5ccda-84b1-4213-d257-dcd59e8e761c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from evaluate import load\n",
        "bertscore = load(\"bertscore\")\n",
        "\n",
        "benchmark_data = pd.read_csv(\"../eval-sets/a-eval-set/seen-data.csv\")\n",
        "\n",
        "for idx, row in benchmark_data.iterrows():\n",
        "    user_query = row[\"Question\"]\n",
        "    correct_answer = row[\"Answer\"]\n",
        "\n",
        "    responses = generate_answer(user_query)\n",
        "    \n",
        "    predictions = [responses.get(\"Response\", \"N/A\")]\n",
        "    references = [correct_answer]\n",
        "    results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Benchmark Query {idx + 1}: {user_query}\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"\\nRAG Response:\\n\", responses.get(\"Response\", \"N/A\"))\n",
        "    print(\"\\n(Benchmark) Answer:\\n\", correct_answer)\n",
        "    print(\"BERT Score == \", results)\n",
        "    print(\"=\"*50 + \"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "CampusConnect",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
