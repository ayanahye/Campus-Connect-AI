{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym5dMYn-9Sum"
      },
      "source": [
        "## Hello, Here's How to use RAG w HF Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNlcwxKR9gXt"
      },
      "source": [
        "Install some dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q0wlrXoS1EP-",
        "outputId": "8b98c2f2-1383-4b44-feaa-6a1c06c96c11"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U bitsandbytes==0.42.0\n",
        "!pip install -q -U peft==0.8.2\n",
        "!pip install -q -U trl==0.7.10\n",
        "!pip install -q -U accelerate==0.27.1\n",
        "!pip install -q -U datasets==2.17.0\n",
        "!pip install -q -U transformers==4.41.0\n",
        "!pip install langchain sentence-transformers chromadb langchainhub\n",
        "!pip install tensorflow\n",
        "!pip install tf-keras\n",
        "!pip install chromadb\n",
        "!pip install langchain-community langchain-core\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DedwIx35-UcR"
      },
      "source": [
        "Get the Model You Want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "M-dvCR_M1qQR"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# get the repository ID for the Gemma 2b model which I am testing with\n",
        "repo_id = \"google/gemma-2-2b-it\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaDCl4Jj-YCQ"
      },
      "source": [
        "Define Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymTffeGN4EH-",
        "outputId": "cc848d1e-8b63-41ce-ea1f-5f877e7e16f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING! max_length is not default parameter.\n",
            "                    max_length was transferred to model_kwargs.\n",
            "                    Please make sure that max_length is what you intended.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# set your own hf token then fetch it here\n",
        "hf_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "\n",
        "# obv params, max_length is max token len for generated text, temp=0.1 means give more predictable and less random results\n",
        "llm = HuggingFaceEndpoint(\n",
        "    task='text-generation',\n",
        "    repo_id=repo_id,\n",
        "    model=\"google/gemma-2-2b-it\",\n",
        "    max_length=1024,\n",
        "    temperature=0.1,\n",
        "    huggingfacehub_api_token=hf_token\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBA-ljP5-bOR"
      },
      "source": [
        "Define Data Sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "UVLl-QTT61Aw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load ur data\n",
        "# health_data = pd.read_csv('../Health-Data-and-Scripts-for-Chatbot/data-with-sources.csv')\n",
        "# work_data = pd.read_csv('../Work-Study-Data-and-Scripts/work-and-education-data.csv')\n",
        "transit_data = pd.read_csv('../Transit-Data-Ques-Ans/vancouver_transit_qa_pairs.csv')\n",
        "\n",
        "# health_data_sample = health_data\n",
        "# work_data_sample = work_data\n",
        "transit_data_sample = transit_data\n",
        "\n",
        "# health_data_sample['text'] = health_data_sample['Question'].fillna('') + ' ' + health_data_sample['Answer'].fillna('')\n",
        "# work_data_sample['text'] = work_data_sample['Theme'].fillna('') + ' ' + work_data_sample['Content'].fillna('')\n",
        "transit_data_sample['text'] = transit_data_sample['question'].fillna('') + ' ' + transit_data_sample['answer'].fillna('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5NPcS-__W2F"
      },
      "source": [
        "Set Embedding Model, and Chroma Client to Interact w Vector Database and Create Collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "JKdxYOca7KfJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/CampusConnect/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "import chromadb\n",
        "\n",
        "# pt model for generating embeddings used pretty often\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "# persistent client to interact w chroma vector store\n",
        "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "# create collections for each data (for testing rn)\n",
        "health_collection = client.get_or_create_collection(name=\"health_docs\")\n",
        "work_collection = client.get_or_create_collection(name=\"work_docs\")\n",
        "transit_collection = client.get_or_create_collection(name=\"transit_docs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOEGkLgl_e2Z"
      },
      "source": [
        "Function to add data to collection by embedding them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lN1Q5d_8jZt",
        "outputId": "5d2003a4-e061-434b-ee7c-c0c852f47c06"
      },
      "outputs": [],
      "source": [
        "def add_data_to_collection(collection, data):\n",
        "    for idx, row in data.iterrows():\n",
        "        try:\n",
        "            # get the embeddings using the embedding model for the documents\n",
        "            embeddings = embedding_model.embed_documents([row['text']])[0]\n",
        "            collection.add(\n",
        "                ids=[str(idx)],\n",
        "                embeddings=[embeddings],\n",
        "                documents=[row['text']]\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error on index {idx}: {e}\")\n",
        "\n",
        "# add data to collections\n",
        "# add_data_to_collection(health_collection, health_data_sample)\n",
        "# add_data_to_collection(work_collection, work_data_sample)\n",
        "add_data_to_collection(transit_collection, transit_data_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn2LQiJq_k9t"
      },
      "source": [
        "Function to now match for releveant document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "TEulNQZw8mDo"
      },
      "outputs": [],
      "source": [
        "def get_relevant_document(query, category):\n",
        "    try:\n",
        "        # get the embedding for the user query using same embedding model\n",
        "        query_embeddings = embedding_model.embed_documents([query])[0]\n",
        "\n",
        "        # choose the correct collection based on the category\n",
        "        if category == \"health\":\n",
        "            collection = health_collection\n",
        "        elif category == \"work\":\n",
        "            collection = work_collection\n",
        "        elif category == \"transit\":\n",
        "            collection = transit_collection\n",
        "        # collection = health_collection if category == \"health\" else work_collection\n",
        "\n",
        "        # query the collection\n",
        "        results = collection.query(query_embeddings=[query_embeddings], n_results=1)\n",
        "\n",
        "        print(f\"Query Results: {results}\")\n",
        "\n",
        "        return results['documents'][0][0] if results['documents'] else None\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV_h8UJa_pGj"
      },
      "source": [
        "Generate Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "EMTYliNl8onj"
      },
      "outputs": [],
      "source": [
        "def generate_answer(query, category):\n",
        "    # b4 rag\n",
        "    output_before_rag = llm.predict(f\"Respond to this question: {query}\")\n",
        "    response_before_rag = output_before_rag\n",
        "\n",
        "    # get the relevant document\n",
        "    relevant_document = get_relevant_document(query, category)\n",
        "    if relevant_document is None:\n",
        "        return f\"Sorry, no relevant document found. Model's response before RAG: {response_before_rag}\"\n",
        "\n",
        "    relevant_document = \" \".join(relevant_document.split())\n",
        "    MAX_DOC_LENGTH = 500\n",
        "    relevant_document = relevant_document[:MAX_DOC_LENGTH]\n",
        "\n",
        "    # rag_prompt = f\"\"\"\n",
        "    # You are a helpful assistant for international students new to B.C. Here is a relevant document:\n",
        "\n",
        "    # {relevant_document}\n",
        "\n",
        "    # Please respond to the following question based on the document above:\n",
        "\n",
        "    # Question: {query}\n",
        "\n",
        "    # Answer:\n",
        "    # \"\"\"\n",
        "    rag_prompt = f\"\"\"\n",
        "    You are a helpful assistant for international students new to B.C. Here is a relevant document:\n",
        "\n",
        "    {relevant_document}\n",
        "\n",
        "    Please respond to the following question based on the document above, if you can't answer anything or it requires the international student to ask a query again, direct them to additional resources like the vancouver transit website or the transit mobile app for transit related queries:\n",
        "\n",
        "    Question: {query}\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    # print(\"Prompt being sent to model:\")\n",
        "    # print(rag_prompt)\n",
        "\n",
        "    # now generate using RAG\n",
        "    output_after_rag = llm.predict(rag_prompt)\n",
        "    # print(\"Output from model:\", output_after_rag)\n",
        "\n",
        "    response_after_rag = output_after_rag\n",
        "\n",
        "    # return both responses to compare\n",
        "    return {\n",
        "        \"Before RAG Response\": response_before_rag,\n",
        "        \"After RAG Response\": response_after_rag\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxtEFTiK_q8E"
      },
      "source": [
        "Example Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVDilNoM8sU8",
        "outputId": "d1198887-bed2-455b-b25e-61c3a084d089"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/CampusConnect/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Results: {'ids': [['729']], 'embeddings': None, 'documents': [['How do I plan a bus trip in Vancouver? You can plan your trip using the TransLink website, Google Maps, or the TransLink mobile app. Enter your starting point and destination, and these tools will show you the best routes, including any transfers needed.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[0.7808047116934143]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/CampusConnect/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User Query: How do I commute in vancouver and how can I get to SFU?\n",
            "Response Before RAG: \n",
            "\n",
            "**Here's a breakdown of commuting options in Vancouver and getting to SFU:**\n",
            "\n",
            "**1. Public Transit:**\n",
            "\n",
            "* **TransLink:** Vancouver's public transit system is extensive and reliable. \n",
            "    * **SkyTrain:** The SkyTrain is the fastest option, connecting major areas like downtown Vancouver, Richmond, and Surrey.  \n",
            "    * **Bus:** Buses are a more affordable option, covering a wider range of routes. \n",
            "    * **SeaBus:** This ferry service connects North Vancouver to downtown Vancouver.\n",
            "* **Getting to SFU:**\n",
            "    * **SkyTrain:** Take the Expo Line from downtown Vancouver to the SFU station.\n",
            "    * **Bus:** Several bus routes connect SFU to various parts of Vancouver. Check TransLink's website for specific routes and schedules.\n",
            "\n",
            "**2. Driving:**\n",
            "\n",
            "* **Traffic:** Vancouver's traffic can be challenging, especially during peak hours. \n",
            "* **Parking:** Parking at SFU can be limited and expensive. \n",
            "* **Alternatives:** Consider carpooling or using ride-sharing services like Uber or Lyft.\n",
            "\n",
            "**3. Cycling:**\n",
            "\n",
            "* **Cycling Infrastructure:** Vancouver has a growing network of bike lanes and paths. \n",
            "* **Safety:** Be aware of traffic and prioritize safety.\n",
            "* **Distance:** Cycling to SFU from downtown Vancouver can be a long journey.\n",
            "\n",
            "**4. Walking:**\n",
            "\n",
            "* **Distance:** Walking to SFU from downtown Vancouver is possible, but it's a long walk. \n",
            "* **Safety:** Be aware of traffic and choose well-lit and safe routes.\n",
            "\n",
            "**Tips for Choosing Your Commute:**\n",
            "\n",
            "* **Time:** Consider your commute time and how it fits into your schedule.\n",
            "* **Cost:** Compare the cost of different options, including fares, parking, and fuel.\n",
            "* **Convenience:** Choose the option that is most convenient for you, considering factors like accessibility and comfort.\n",
            "* **Environment:** Consider the environmental impact of your commute.\n",
            "\n",
            "\n",
            "**Resources:**\n",
            "\n",
            "* **TransLink:** [https://www.translink.ca/](https://www.translink.ca/)\n",
            "* **SFU Website:** [https://www.sfu.ca/](https://www.sfu.ca/)\n",
            "\n",
            "\n",
            "Let me know if you have any other questions! \n",
            "\n",
            "Response After RAG: To plan your trip using public transportation in Vancouver, you can use the TransLink website, Google Maps, or the TransLink mobile app. \n",
            "    Enter your starting point and destination, and these tools will show you the best routes, including any transfers needed. \n",
            "\n",
            "    For getting to SFU, you can use the same tools to plan your trip. \n",
            "    \n",
            "    To get to SFU, you can use the SkyTrain and bus. \n",
            "    \n",
            "    Here are some tips for using the SkyTrain:\n",
            "    * The SkyTrain runs from downtown Vancouver to SFU.\n",
            "    * You can purchase a Compass Card for easy and convenient travel.\n",
            "    * The SkyTrain is a fast and efficient way to get to SFU.\n",
            "    \n",
            "    Here are some tips for using the bus:\n",
            "    * The bus routes to SFU are available on the TransLink website.\n",
            "    * You can purchase a Compass Card for easy and convenient travel.\n",
            "    * The bus is a more affordable option than the SkyTrain.\n",
            "\n",
            "    You can find more information about the SkyTrain and bus routes on the TransLink website. \n",
            "    \n",
            "    You can also use the TransLink mobile app for easy access to real-time transit information. \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n"
          ]
        }
      ],
      "source": [
        "user_query = \"How do I commute in vancouver and how can I get to SFU?\"\n",
        "# user_query = \"What do I need to do to apply for MSP coverage in B.C.?\"\n",
        "category = \"transit\"\n",
        "# category = \"health\"\n",
        "responses = generate_answer(user_query, category)\n",
        "\n",
        "print(\"User Query:\", user_query)\n",
        "print(\"Response Before RAG:\", responses[\"Before RAG Response\"])\n",
        "print(\"Response After RAG:\", responses[\"After RAG Response\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXMwMcnvAWz_",
        "outputId": "ffe2ba21-49e0-49d3-a490-c2ea767da941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of documents in health collection: 2\n",
            "Number of documents in work collection: 2\n"
          ]
        }
      ],
      "source": [
        "# verify\n",
        "health_docs = health_collection.get()\n",
        "print(\"Number of documents in health collection:\", len(health_docs['documents']))\n",
        "\n",
        "work_docs = work_collection.get()\n",
        "print(\"Number of documents in work collection:\", len(work_docs['documents']))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "CampusConnect",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
