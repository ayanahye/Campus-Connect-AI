{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym5dMYn-9Sum"
      },
      "source": [
        "## Hello, Here's How to use RAG w HF Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNlcwxKR9gXt"
      },
      "source": [
        "Install some dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q0wlrXoS1EP-",
        "outputId": "8b98c2f2-1383-4b44-feaa-6a1c06c96c11"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U bitsandbytes==0.42.0\n",
        "!pip install -q -U peft==0.8.2\n",
        "!pip install -q -U trl==0.7.10\n",
        "!pip install -q -U accelerate==0.27.1\n",
        "!pip install -q -U datasets==2.17.0\n",
        "!pip install -q -U transformers==4.41.0\n",
        "!pip install langchain sentence-transformers chromadb langchainhub\n",
        "!pip install tensorflow\n",
        "!pip install tf-keras\n",
        "!pip install chromadb\n",
        "!pip install langchain-community langchain-core\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DedwIx35-UcR"
      },
      "source": [
        "Get the Model You Want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "M-dvCR_M1qQR"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# get the repository ID for the Gemma 2b model which I am testing with\n",
        "repo_id = \"google/gemma-2-2b-it\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaDCl4Jj-YCQ"
      },
      "source": [
        "Define Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymTffeGN4EH-",
        "outputId": "cc848d1e-8b63-41ce-ea1f-5f877e7e16f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING! max_length is not default parameter.\n",
            "                    max_length was transferred to model_kwargs.\n",
            "                    Please make sure that max_length is what you intended.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# set your own hf token then fetch it here\n",
        "hf_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "\n",
        "# obv params, max_length is max token len for generated text, temp=0.1 means give more predictable and less random results\n",
        "llm = HuggingFaceEndpoint(\n",
        "    task='text-generation',\n",
        "    repo_id=repo_id,\n",
        "    model=\"google/gemma-2-2b-it\",\n",
        "    max_length=1024,\n",
        "    temperature=0.1,\n",
        "    huggingfacehub_api_token=hf_token\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBA-ljP5-bOR"
      },
      "source": [
        "Define Data Sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UVLl-QTT61Aw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load ur data\n",
        "# health_data = pd.read_csv('../Health-Data-and-Scripts-for-Chatbot/data-with-sources.csv')\n",
        "# work_data = pd.read_csv('../Work-Study-Data-and-Scripts/work-and-education-data.csv')\n",
        "transit_data = pd.read_csv('../Transit-Data-Ques-Ans/vancouver_transit_qa_pairs.csv')\n",
        "\n",
        "# health_data_sample = health_data\n",
        "# work_data_sample = work_data\n",
        "transit_data_sample = transit_data\n",
        "\n",
        "# health_data_sample['text'] = health_data_sample['Question'].fillna('') + ' ' + health_data_sample['Answer'].fillna('')\n",
        "# work_data_sample['text'] = work_data_sample['Theme'].fillna('') + ' ' + work_data_sample['Content'].fillna('')\n",
        "transit_data_sample['text'] = transit_data_sample['question'].fillna('') + ' ' + transit_data_sample['answer'].fillna('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5NPcS-__W2F"
      },
      "source": [
        "Set Embedding Model, and Chroma Client to Interact w Vector Database and Create Collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JKdxYOca7KfJ"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "import chromadb\n",
        "\n",
        "# pt model for generating embeddings used pretty often\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "# persistent client to interact w chroma vector store\n",
        "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "# create collections for each data (for testing rn)\n",
        "health_collection = client.get_or_create_collection(name=\"health_docs\")\n",
        "work_collection = client.get_or_create_collection(name=\"work_docs\")\n",
        "transit_collection = client.get_or_create_collection(name=\"transit_docs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOEGkLgl_e2Z"
      },
      "source": [
        "Function to add data to collection by embedding them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lN1Q5d_8jZt",
        "outputId": "5d2003a4-e061-434b-ee7c-c0c852f47c06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Insert of existing embedding ID: 0\n",
            "Add of existing embedding ID: 0\n",
            "Insert of existing embedding ID: 1\n",
            "Add of existing embedding ID: 1\n",
            "Insert of existing embedding ID: 2\n",
            "Add of existing embedding ID: 2\n",
            "Insert of existing embedding ID: 3\n",
            "Add of existing embedding ID: 3\n",
            "Insert of existing embedding ID: 4\n",
            "Add of existing embedding ID: 4\n",
            "Insert of existing embedding ID: 5\n",
            "Add of existing embedding ID: 5\n",
            "Insert of existing embedding ID: 6\n",
            "Add of existing embedding ID: 6\n",
            "Insert of existing embedding ID: 7\n",
            "Add of existing embedding ID: 7\n",
            "Insert of existing embedding ID: 8\n",
            "Add of existing embedding ID: 8\n",
            "Insert of existing embedding ID: 9\n",
            "Add of existing embedding ID: 9\n",
            "Insert of existing embedding ID: 10\n",
            "Add of existing embedding ID: 10\n",
            "Insert of existing embedding ID: 11\n",
            "Add of existing embedding ID: 11\n",
            "Insert of existing embedding ID: 12\n",
            "Add of existing embedding ID: 12\n",
            "Insert of existing embedding ID: 13\n",
            "Add of existing embedding ID: 13\n",
            "Insert of existing embedding ID: 14\n",
            "Add of existing embedding ID: 14\n",
            "Insert of existing embedding ID: 15\n",
            "Add of existing embedding ID: 15\n",
            "Insert of existing embedding ID: 16\n",
            "Add of existing embedding ID: 16\n",
            "Insert of existing embedding ID: 17\n",
            "Add of existing embedding ID: 17\n",
            "Insert of existing embedding ID: 18\n",
            "Add of existing embedding ID: 18\n",
            "Insert of existing embedding ID: 19\n",
            "Add of existing embedding ID: 19\n",
            "Insert of existing embedding ID: 20\n",
            "Add of existing embedding ID: 20\n",
            "Insert of existing embedding ID: 21\n",
            "Add of existing embedding ID: 21\n",
            "Insert of existing embedding ID: 22\n",
            "Add of existing embedding ID: 22\n",
            "Insert of existing embedding ID: 23\n",
            "Add of existing embedding ID: 23\n",
            "Insert of existing embedding ID: 24\n",
            "Add of existing embedding ID: 24\n",
            "Insert of existing embedding ID: 25\n",
            "Add of existing embedding ID: 25\n",
            "Insert of existing embedding ID: 26\n",
            "Add of existing embedding ID: 26\n",
            "Insert of existing embedding ID: 27\n",
            "Add of existing embedding ID: 27\n",
            "Insert of existing embedding ID: 28\n",
            "Add of existing embedding ID: 28\n",
            "Insert of existing embedding ID: 29\n",
            "Add of existing embedding ID: 29\n",
            "Insert of existing embedding ID: 30\n",
            "Add of existing embedding ID: 30\n",
            "Insert of existing embedding ID: 31\n",
            "Add of existing embedding ID: 31\n",
            "Insert of existing embedding ID: 32\n",
            "Add of existing embedding ID: 32\n",
            "Insert of existing embedding ID: 33\n",
            "Add of existing embedding ID: 33\n",
            "Insert of existing embedding ID: 34\n",
            "Add of existing embedding ID: 34\n",
            "Insert of existing embedding ID: 35\n",
            "Add of existing embedding ID: 35\n",
            "Insert of existing embedding ID: 36\n",
            "Add of existing embedding ID: 36\n",
            "Insert of existing embedding ID: 37\n",
            "Add of existing embedding ID: 37\n",
            "Insert of existing embedding ID: 38\n",
            "Add of existing embedding ID: 38\n",
            "Insert of existing embedding ID: 39\n",
            "Add of existing embedding ID: 39\n",
            "Insert of existing embedding ID: 40\n",
            "Add of existing embedding ID: 40\n",
            "Insert of existing embedding ID: 41\n",
            "Add of existing embedding ID: 41\n",
            "Insert of existing embedding ID: 42\n",
            "Add of existing embedding ID: 42\n",
            "Insert of existing embedding ID: 43\n",
            "Add of existing embedding ID: 43\n",
            "Insert of existing embedding ID: 44\n",
            "Add of existing embedding ID: 44\n",
            "Insert of existing embedding ID: 45\n",
            "Add of existing embedding ID: 45\n",
            "Insert of existing embedding ID: 46\n",
            "Add of existing embedding ID: 46\n",
            "Insert of existing embedding ID: 47\n",
            "Add of existing embedding ID: 47\n",
            "Insert of existing embedding ID: 48\n",
            "Add of existing embedding ID: 48\n",
            "Insert of existing embedding ID: 49\n",
            "Add of existing embedding ID: 49\n",
            "Insert of existing embedding ID: 50\n",
            "Add of existing embedding ID: 50\n",
            "Insert of existing embedding ID: 51\n",
            "Add of existing embedding ID: 51\n",
            "Insert of existing embedding ID: 52\n",
            "Add of existing embedding ID: 52\n",
            "Insert of existing embedding ID: 53\n",
            "Add of existing embedding ID: 53\n",
            "Insert of existing embedding ID: 54\n",
            "Add of existing embedding ID: 54\n",
            "Insert of existing embedding ID: 55\n",
            "Add of existing embedding ID: 55\n",
            "Insert of existing embedding ID: 56\n",
            "Add of existing embedding ID: 56\n",
            "Insert of existing embedding ID: 57\n",
            "Add of existing embedding ID: 57\n",
            "Insert of existing embedding ID: 58\n",
            "Add of existing embedding ID: 58\n",
            "Insert of existing embedding ID: 59\n",
            "Add of existing embedding ID: 59\n",
            "Insert of existing embedding ID: 60\n",
            "Add of existing embedding ID: 60\n",
            "Insert of existing embedding ID: 61\n",
            "Add of existing embedding ID: 61\n",
            "Insert of existing embedding ID: 62\n",
            "Add of existing embedding ID: 62\n",
            "Insert of existing embedding ID: 63\n",
            "Add of existing embedding ID: 63\n",
            "Insert of existing embedding ID: 64\n",
            "Add of existing embedding ID: 64\n",
            "Insert of existing embedding ID: 65\n",
            "Add of existing embedding ID: 65\n",
            "Insert of existing embedding ID: 66\n",
            "Add of existing embedding ID: 66\n",
            "Insert of existing embedding ID: 67\n",
            "Add of existing embedding ID: 67\n",
            "Insert of existing embedding ID: 68\n",
            "Add of existing embedding ID: 68\n",
            "Insert of existing embedding ID: 69\n",
            "Add of existing embedding ID: 69\n",
            "Insert of existing embedding ID: 70\n",
            "Add of existing embedding ID: 70\n",
            "Insert of existing embedding ID: 71\n",
            "Add of existing embedding ID: 71\n",
            "Insert of existing embedding ID: 72\n",
            "Add of existing embedding ID: 72\n",
            "Insert of existing embedding ID: 73\n",
            "Add of existing embedding ID: 73\n",
            "Insert of existing embedding ID: 74\n",
            "Add of existing embedding ID: 74\n",
            "Insert of existing embedding ID: 75\n",
            "Add of existing embedding ID: 75\n",
            "Insert of existing embedding ID: 76\n",
            "Add of existing embedding ID: 76\n",
            "Insert of existing embedding ID: 77\n",
            "Add of existing embedding ID: 77\n",
            "Insert of existing embedding ID: 78\n",
            "Add of existing embedding ID: 78\n",
            "Insert of existing embedding ID: 79\n",
            "Add of existing embedding ID: 79\n",
            "Insert of existing embedding ID: 80\n",
            "Add of existing embedding ID: 80\n",
            "Insert of existing embedding ID: 81\n",
            "Add of existing embedding ID: 81\n",
            "Insert of existing embedding ID: 82\n",
            "Add of existing embedding ID: 82\n",
            "Insert of existing embedding ID: 83\n",
            "Add of existing embedding ID: 83\n",
            "Insert of existing embedding ID: 84\n",
            "Add of existing embedding ID: 84\n",
            "Insert of existing embedding ID: 85\n",
            "Add of existing embedding ID: 85\n",
            "Insert of existing embedding ID: 86\n",
            "Add of existing embedding ID: 86\n",
            "Insert of existing embedding ID: 87\n",
            "Add of existing embedding ID: 87\n",
            "Insert of existing embedding ID: 88\n",
            "Add of existing embedding ID: 88\n",
            "Insert of existing embedding ID: 89\n",
            "Add of existing embedding ID: 89\n",
            "Insert of existing embedding ID: 90\n",
            "Add of existing embedding ID: 90\n",
            "Insert of existing embedding ID: 91\n",
            "Add of existing embedding ID: 91\n",
            "Insert of existing embedding ID: 92\n",
            "Add of existing embedding ID: 92\n",
            "Insert of existing embedding ID: 93\n",
            "Add of existing embedding ID: 93\n",
            "Insert of existing embedding ID: 94\n",
            "Add of existing embedding ID: 94\n",
            "Insert of existing embedding ID: 95\n",
            "Add of existing embedding ID: 95\n",
            "Insert of existing embedding ID: 96\n",
            "Add of existing embedding ID: 96\n",
            "Insert of existing embedding ID: 97\n",
            "Add of existing embedding ID: 97\n",
            "Insert of existing embedding ID: 98\n",
            "Add of existing embedding ID: 98\n",
            "Insert of existing embedding ID: 99\n",
            "Add of existing embedding ID: 99\n",
            "Insert of existing embedding ID: 100\n",
            "Add of existing embedding ID: 100\n",
            "Insert of existing embedding ID: 101\n",
            "Add of existing embedding ID: 101\n",
            "Insert of existing embedding ID: 102\n",
            "Add of existing embedding ID: 102\n",
            "Insert of existing embedding ID: 103\n",
            "Add of existing embedding ID: 103\n",
            "Insert of existing embedding ID: 104\n",
            "Add of existing embedding ID: 104\n",
            "Insert of existing embedding ID: 105\n",
            "Add of existing embedding ID: 105\n",
            "Insert of existing embedding ID: 106\n",
            "Add of existing embedding ID: 106\n",
            "Insert of existing embedding ID: 107\n",
            "Add of existing embedding ID: 107\n",
            "Insert of existing embedding ID: 108\n",
            "Add of existing embedding ID: 108\n",
            "Insert of existing embedding ID: 109\n",
            "Add of existing embedding ID: 109\n",
            "Insert of existing embedding ID: 110\n",
            "Add of existing embedding ID: 110\n",
            "Insert of existing embedding ID: 111\n",
            "Add of existing embedding ID: 111\n",
            "Insert of existing embedding ID: 112\n",
            "Add of existing embedding ID: 112\n",
            "Insert of existing embedding ID: 113\n",
            "Add of existing embedding ID: 113\n",
            "Insert of existing embedding ID: 114\n",
            "Add of existing embedding ID: 114\n",
            "Insert of existing embedding ID: 115\n",
            "Add of existing embedding ID: 115\n",
            "Insert of existing embedding ID: 116\n",
            "Add of existing embedding ID: 116\n",
            "Insert of existing embedding ID: 117\n",
            "Add of existing embedding ID: 117\n",
            "Insert of existing embedding ID: 118\n",
            "Add of existing embedding ID: 118\n",
            "Insert of existing embedding ID: 119\n",
            "Add of existing embedding ID: 119\n",
            "Insert of existing embedding ID: 120\n",
            "Add of existing embedding ID: 120\n",
            "Insert of existing embedding ID: 121\n",
            "Add of existing embedding ID: 121\n",
            "Insert of existing embedding ID: 122\n",
            "Add of existing embedding ID: 122\n",
            "Insert of existing embedding ID: 123\n",
            "Add of existing embedding ID: 123\n",
            "Insert of existing embedding ID: 124\n",
            "Add of existing embedding ID: 124\n",
            "Insert of existing embedding ID: 125\n",
            "Add of existing embedding ID: 125\n",
            "Insert of existing embedding ID: 126\n",
            "Add of existing embedding ID: 126\n",
            "Insert of existing embedding ID: 127\n",
            "Add of existing embedding ID: 127\n",
            "Insert of existing embedding ID: 128\n",
            "Add of existing embedding ID: 128\n",
            "Insert of existing embedding ID: 129\n",
            "Add of existing embedding ID: 129\n",
            "Insert of existing embedding ID: 130\n",
            "Add of existing embedding ID: 130\n",
            "Insert of existing embedding ID: 131\n",
            "Add of existing embedding ID: 131\n",
            "Insert of existing embedding ID: 132\n",
            "Add of existing embedding ID: 132\n",
            "Insert of existing embedding ID: 133\n",
            "Add of existing embedding ID: 133\n",
            "Insert of existing embedding ID: 134\n",
            "Add of existing embedding ID: 134\n",
            "Insert of existing embedding ID: 135\n",
            "Add of existing embedding ID: 135\n",
            "Insert of existing embedding ID: 136\n",
            "Add of existing embedding ID: 136\n",
            "Insert of existing embedding ID: 137\n",
            "Add of existing embedding ID: 137\n",
            "Insert of existing embedding ID: 138\n",
            "Add of existing embedding ID: 138\n",
            "Insert of existing embedding ID: 139\n",
            "Add of existing embedding ID: 139\n",
            "Insert of existing embedding ID: 140\n",
            "Add of existing embedding ID: 140\n",
            "Insert of existing embedding ID: 141\n",
            "Add of existing embedding ID: 141\n",
            "Insert of existing embedding ID: 142\n",
            "Add of existing embedding ID: 142\n",
            "Insert of existing embedding ID: 143\n",
            "Add of existing embedding ID: 143\n",
            "Insert of existing embedding ID: 144\n",
            "Add of existing embedding ID: 144\n",
            "Insert of existing embedding ID: 145\n",
            "Add of existing embedding ID: 145\n"
          ]
        }
      ],
      "source": [
        "def add_data_to_collection(collection, data):\n",
        "    for idx, row in data.iterrows():\n",
        "        try:\n",
        "            # get the embeddings using the embedding model for the documents\n",
        "            embeddings = embedding_model.embed_documents([row['text']])[0]\n",
        "            collection.add(\n",
        "                ids=[str(idx)],\n",
        "                embeddings=[embeddings],\n",
        "                documents=[row['text']]\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error on index {idx}: {e}\")\n",
        "\n",
        "# add data to collections\n",
        "# add_data_to_collection(health_collection, health_data_sample)\n",
        "# add_data_to_collection(work_collection, work_data_sample)\n",
        "add_data_to_collection(transit_collection, transit_data_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn2LQiJq_k9t"
      },
      "source": [
        "Function to now match for releveant document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "TEulNQZw8mDo"
      },
      "outputs": [],
      "source": [
        "def get_relevant_document(query, category):\n",
        "    try:\n",
        "        # get the embedding for the user query using same embedding model\n",
        "        query_embeddings = embedding_model.embed_documents([query])[0]\n",
        "\n",
        "        # choose the correct collection based on the category\n",
        "        if category == \"health\":\n",
        "            collection = health_collection\n",
        "        elif category == \"work\":\n",
        "            collection = work_collection\n",
        "        elif category == \"transit\":\n",
        "            collection = transit_collection\n",
        "        # collection = health_collection if category == \"health\" else work_collection\n",
        "\n",
        "        # query the collection\n",
        "        results = collection.query(query_embeddings=[query_embeddings], n_results=1)\n",
        "\n",
        "        print(f\"Query Results: {results}\")\n",
        "\n",
        "        return results['documents'][0][0] if results['documents'] else None\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV_h8UJa_pGj"
      },
      "source": [
        "Generate Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "EMTYliNl8onj"
      },
      "outputs": [],
      "source": [
        "def generate_answer(query, category):\n",
        "    # b4 rag\n",
        "    output_before_rag = llm.predict(f\"Respond to this question: {query}\")\n",
        "    response_before_rag = output_before_rag\n",
        "\n",
        "    # get the relevant document\n",
        "    relevant_document = get_relevant_document(query, category)\n",
        "    if relevant_document is None:\n",
        "        return f\"Sorry, no relevant document found. Model's response before RAG: {response_before_rag}\"\n",
        "\n",
        "    relevant_document = \" \".join(relevant_document.split())\n",
        "    MAX_DOC_LENGTH = 500\n",
        "    relevant_document = relevant_document[:MAX_DOC_LENGTH]\n",
        "\n",
        "    # rag_prompt = f\"\"\"\n",
        "    # You are a helpful assistant for international students new to B.C. Here is a relevant document:\n",
        "\n",
        "    # {relevant_document}\n",
        "\n",
        "    # Please respond to the following question based on the document above:\n",
        "\n",
        "    # Question: {query}\n",
        "\n",
        "    # Answer:\n",
        "    # \"\"\"\n",
        "    rag_prompt = f\"\"\"\n",
        "    You are a helpful assistant for international students new to B.C. Here is a relevant document:\n",
        "\n",
        "    {relevant_document}\n",
        "\n",
        "    Please respond to the following question based on the document above, if you can't answer anything or it requires the international student to ask a query again, direct them to additional resources like the vancouver transit website or the transit mobile app for transit related queries:\n",
        "\n",
        "    Question: {query}\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    # print(\"Prompt being sent to model:\")\n",
        "    # print(rag_prompt)\n",
        "\n",
        "    # now generate using RAG\n",
        "    output_after_rag = llm.predict(rag_prompt)\n",
        "    # print(\"Output from model:\", output_after_rag)\n",
        "\n",
        "    response_after_rag = output_after_rag\n",
        "\n",
        "    # return both responses to compare\n",
        "    return {\n",
        "        \"Before RAG Response\": response_before_rag,\n",
        "        \"After RAG Response\": response_after_rag\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxtEFTiK_q8E"
      },
      "source": [
        "Example Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVDilNoM8sU8",
        "outputId": "d1198887-bed2-455b-b25e-61c3a084d089"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/CampusConnect/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Results: {'ids': [['131']], 'embeddings': None, 'documents': [['How do I plan a bus trip in Vancouver? You can plan your trip using the TransLink website, Google Maps, or the TransLink mobile app. Enter your starting point and destination, and these tools will show you the best routes, including any transfers needed.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[0.7808046340942383]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/CampusConnect/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User Query: How do I commute in vancouver and how can I get to SFU?\n",
            "Response Before RAG: \n",
            "\n",
            "**Here's a breakdown of commuting options in Vancouver and how to get to SFU:**\n",
            "\n",
            "**1. Public Transit:**\n",
            "\n",
            "* **TransLink:** Vancouver's public transit system is extensive and reliable. \n",
            "    * **SkyTrain:** The SkyTrain is the fastest option, connecting major areas like downtown Vancouver, Richmond, and Surrey. SFU is served by the Millennium Line.\n",
            "    * **Bus:** Buses are a more affordable option, covering a wider range of routes.  \n",
            "    * **SeaBus:** This ferry service connects North Vancouver to downtown Vancouver, offering a scenic route.\n",
            "* **Getting to SFU:**\n",
            "    * **SkyTrain:** Take the Millennium Line from Waterfront Station to SFU.\n",
            "    * **Bus:** Several bus routes connect SFU to various parts of Vancouver. Check TransLink's website for specific routes and schedules.\n",
            "\n",
            "**2. Driving:**\n",
            "\n",
            "* **Traffic:** Vancouver traffic can be challenging, especially during peak hours.\n",
            "* **Parking:** Parking on campus can be limited and expensive.\n",
            "* **Alternatives:** Consider carpooling or using ride-sharing services like Uber or Lyft.\n",
            "\n",
            "**3. Cycling:**\n",
            "\n",
            "* **Cycling Infrastructure:** Vancouver has a growing network of bike lanes and paths.\n",
            "* **Safety:** Be aware of traffic and prioritize safety.\n",
            "* **Distance:** Cycling to SFU from downtown Vancouver can be a long journey.\n",
            "\n",
            "**4. Walking:**\n",
            "\n",
            "* **Distance:** Walking to SFU from downtown Vancouver is possible, but it's a long walk.\n",
            "\n",
            "**Tips for Commuting:**\n",
            "\n",
            "* **Plan Ahead:** Check TransLink's website or app for real-time transit information, including delays and service disruptions.\n",
            "* **Purchase a Compass Card:** This rechargeable card makes it easy to pay for transit fares.\n",
            "* **Consider a Monthly Pass:** If you commute frequently, a monthly pass can save you money.\n",
            "* **Explore Bike Sharing:** Vancouver has a bike-sharing program called Mobi that offers convenient access to bikes.\n",
            "\n",
            "**Resources:**\n",
            "\n",
            "* **TransLink Website:** https://www.translink.ca/\n",
            "* **SFU Website:** https://www.sfu.ca/\n",
            "\n",
            "**Remember:** The best commuting option for you will depend on your individual needs and preferences. \n",
            "\n",
            "Response After RAG: To plan your trip using the TransLink website, Google Maps, or the TransLink mobile app, enter your starting point and destination. These tools will show you the best routes, including any transfers needed. \n",
            "\n",
            "    For SFU, you can use the same tools to plan your trip. \n",
            "    \n",
            "    You can also check out the SFU website for more information about getting to campus. \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n",
            "    \n"
          ]
        }
      ],
      "source": [
        "user_query = \"How do I commute in vancouver and how can I get to SFU?\"\n",
        "# user_query = \"What do I need to do to apply for MSP coverage in B.C.?\"\n",
        "category = \"transit\"\n",
        "# category = \"health\"\n",
        "responses = generate_answer(user_query, category)\n",
        "\n",
        "print(\"User Query:\", user_query)\n",
        "print(\"Response Before RAG:\", responses[\"Before RAG Response\"])\n",
        "print(\"Response After RAG:\", responses[\"After RAG Response\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXMwMcnvAWz_",
        "outputId": "ffe2ba21-49e0-49d3-a490-c2ea767da941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of documents in health collection: 76\n",
            "Number of documents in work collection: 878\n"
          ]
        }
      ],
      "source": [
        "# verify\n",
        "health_docs = health_collection.get()\n",
        "print(\"Number of documents in health collection:\", len(health_docs['documents']))\n",
        "\n",
        "work_docs = work_collection.get()\n",
        "print(\"Number of documents in work collection:\", len(work_docs['documents']))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "CampusConnect",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
