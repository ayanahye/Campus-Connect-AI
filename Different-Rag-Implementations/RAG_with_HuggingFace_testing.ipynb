{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym5dMYn-9Sum"
      },
      "source": [
        "## Hello, Here's How to use RAG w HF Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNlcwxKR9gXt"
      },
      "source": [
        "Install some dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0wlrXoS1EP-",
        "outputId": "66a965ad-b8ac-473d-a552-c78fd2799acc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: langchainhub in /usr/local/lib/python3.11/dist-packages (0.1.21)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.47)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
            "  Using cached transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.29.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.12)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.21.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (24.2)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (2.32.0.20250306)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.46.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.31.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Collecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Using cached transformers-4.50.1-py3-none-any.whl (10.2 MB)\n",
            "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.1\n",
            "    Uninstalling transformers-4.38.1:\n",
            "      Successfully uninstalled transformers-4.38.1\n",
            "Successfully installed tokenizers-0.21.1 transformers-4.50.1\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.47)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.21)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.10.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (0.3.7)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U peft==0.8.2\n",
        "!pip install -q -U trl==0.7.10\n",
        "!pip install -q -U accelerate==0.27.1\n",
        "!pip install -q -U datasets==2.17.0\n",
        "!pip install -q -U transformers==4.38.1\n",
        "!pip install langchain sentence-transformers chromadb langchainhub\n",
        "\n",
        "!pip install langchain-community langchain-core"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DedwIx35-UcR"
      },
      "source": [
        "Get the Model You Want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hu5dP1rbDv0E",
        "outputId": "934dafda-28f1-4851-cb18-0ecd9d07b7e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optimum[neural-compressor] in /usr/local/lib/python3.11/dist-packages (1.24.0)\n",
            "Requirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.11/dist-packages (from optimum[neural-compressor]) (4.48.3)\n",
            "Collecting transformers>=4.29 (from optimum[neural-compressor])\n",
            "  Using cached transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.11/dist-packages (from optimum[neural-compressor]) (2.6.0+cu124)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from optimum[neural-compressor]) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optimum[neural-compressor]) (2.0.2)\n",
            "Collecting numpy (from optimum[neural-compressor])\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from optimum[neural-compressor]) (0.29.3)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/huggingface-hub/\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: optimum-intel>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.22.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (2023.10.0)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.8.0->optimum[neural-compressor])\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (4.12.2)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.8.0->optimum[neural-compressor])\n",
            "  Downloading typing_extensions-4.13.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: datasets>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (2.17.0)\n",
            "Collecting datasets>=1.4.0 (from optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Using cached datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (75.1.0)\n",
            "Collecting setuptools (from optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Using cached setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.14.1)\n",
            "Collecting scipy (from optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.17.0)\n",
            "Collecting neural-compressor>3.0 (from neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading neural_compressor-3.3-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (0.27.1)\n",
            "Collecting accelerate (from optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting transformers>=4.29 (from optimum[neural-compressor])\n",
            "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[neural-compressor]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11->optimum[neural-compressor]) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum[neural-compressor]) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum[neural-compressor]) (0.5.3)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers>=4.29->optimum[neural-compressor])\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (18.1.0)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (2.2.2)\n",
            "Collecting pandas (from datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (0.70.16)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.8.0->optimum[neural-compressor])\n",
            "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (3.11.14)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.2.18)\n",
            "Collecting numpy (from optimum[neural-compressor])\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (11.1.0)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (3.15.1)\n",
            "Collecting prettytable (from neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading prettytable-3.16.0-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (5.9.5)\n",
            "Collecting psutil (from neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (2.0.8)\n",
            "Collecting schema (from neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.6.1)\n",
            "Collecting numpy (from optimum[neural-compressor])\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (2.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11->optimum[neural-compressor]) (3.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (5.29.4)\n",
            "Collecting protobuf>=3.20.2 (from onnx->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading protobuf-6.30.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.13->neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (0.3.0)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.18.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (2.8.2)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (2025.1)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (2025.1)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (0.2.13)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools->neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (3.10.0)\n",
            "Collecting matplotlib>=2.1.0 (from pycocotools->neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (2.27.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (3.2.1)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib>=2.1.0->pycocotools->neural-compressor>3.0->neural-compressor[pt]>3.0; extra == \"neural-compressor\"->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor])\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.4.0->optimum-intel>=1.18.0->optimum-intel[neural-compressor]>=1.18.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.17.0)\n",
            "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Downloading neural_compressor-3.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.5.2-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
            "Downloading protobuf-6.30.1-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.2/316.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prettytable-3.16.0-py3-none-any.whl (33 kB)\n",
            "Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.5/232.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: schema, pytz, tzdata, typing-extensions, setuptools, python-dateutil, pyparsing, pyarrow, psutil, protobuf, propcache, prettytable, numpy, fsspec, scipy, pandas, tokenizers, matplotlib, transformers, accelerate, neural-compressor, datasets\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.1\n",
            "    Uninstalling tzdata-2025.1:\n",
            "      Successfully uninstalled tzdata-2025.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.1.0\n",
            "    Uninstalling setuptools-75.1.0:\n",
            "      Successfully uninstalled setuptools-75.1.0\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.1\n",
            "    Uninstalling pyparsing-3.2.1:\n",
            "      Successfully uninstalled pyparsing-3.2.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: propcache\n",
            "    Found existing installation: propcache 0.3.0\n",
            "    Uninstalling propcache-0.3.0:\n",
            "      Successfully uninstalled propcache-0.3.0\n",
            "  Attempting uninstall: prettytable\n",
            "    Found existing installation: prettytable 3.15.1\n",
            "    Uninstalling prettytable-3.15.1:\n",
            "      Successfully uninstalled prettytable-3.15.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.10.0\n",
            "    Uninstalling fsspec-2023.10.0:\n",
            "      Successfully uninstalled fsspec-2023.10.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.27.1\n",
            "    Uninstalling accelerate-0.27.1:\n",
            "      Successfully uninstalled accelerate-0.27.1\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.17.0\n",
            "    Uninstalling datasets-2.17.0:\n",
            "      Successfully uninstalled datasets-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "langchain-community 0.3.20 requires numpy<3,>=1.26.2, but you have numpy 1.23.5 which is incompatible.\n",
            "opentelemetry-proto 1.31.1 requires protobuf<6.0,>=5.0, but you have protobuf 6.30.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "google-cloud-firestore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "wandb 0.19.8 requires protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", but you have protobuf 6.30.1 which is incompatible.\n",
            "blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "bigframes 1.41.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "google-cloud-aiplatform 1.84.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.30.1 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 6.30.1 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.30.1 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.30.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-1.5.2 datasets-3.4.1 fsspec-2024.12.0 matplotlib-3.10.1 neural-compressor-3.3 numpy-1.23.5 pandas-2.2.3 prettytable-3.16.0 propcache-0.3.1 protobuf-6.30.1 psutil-7.0.0 pyarrow-19.0.1 pyparsing-3.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 schema-0.7.7 scipy-1.15.2 setuptools-78.1.0 tokenizers-0.20.3 transformers-4.45.2 typing-extensions-4.13.0 tzdata-2025.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "7cd122e84d574c96879f0259d755bad1",
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "accelerate",
                  "dateutil",
                  "numpy",
                  "psutil",
                  "pyarrow",
                  "pytz",
                  "setuptools",
                  "transformers"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#!pip install --upgrade --upgrade-strategy eager \"optimum[neural-compressor]\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgrfSeOhCriu",
        "outputId": "8d14b180-3ed2-4ef0-a90b-655bca22ce80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.11/dist-packages (0.18.0)\n"
          ]
        }
      ],
      "source": [
        "#!pip install fuzzywuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG8Dqg_6JcML",
        "outputId": "bc56b49a-217e-4008-904b-a12dfaab0791"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optimum in /usr/local/lib/python3.11/dist-packages (1.24.0)\n",
            "Requirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.11/dist-packages (from optimum) (4.45.2)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.11/dist-packages (from optimum) (2.6.0+cu124)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from optimum) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optimum) (2.2.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from optimum) (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (2024.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11->optimum) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum) (0.5.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum) (0.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11->optimum) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "#!pip install optimum\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "M-dvCR_M1qQR"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "import chromadb\n",
        "\n",
        "import time\n",
        "import uuid\n",
        "#from fuzzywuzzy import fuzz\n",
        "#from optimum.quantization import QuantizeruenceClassification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBaYgY2WJEZF",
        "outputId": "21a14e6b-53e7-43b2-c3f9-db633b1d4bcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.23.5)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "neural-compressor 3.3 requires numpy<2.0, but you have numpy 2.2.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.30.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4\n"
          ]
        }
      ],
      "source": [
        "#pip install numpy --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaDCl4Jj-YCQ"
      },
      "source": [
        "Define Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymTffeGN4EH-",
        "outputId": "bb3e6fd3-e3c0-4b39-950f-a3172095129d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 2048)\n",
              "    (layers): ModuleList(\n",
              "      (0-15): 16 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaSdpaAttention(\n",
              "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
              "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
              "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
              "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
              "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# set your own hf token then fetch it here\n",
        "hf_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "\n",
        "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, token=hf_token)\n",
        "\n",
        "model.half()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBA-ljP5-bOR"
      },
      "source": [
        "Define Data Sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UVLl-QTT61Aw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_names = [\n",
        "    \"study_permit_general\",\n",
        "    \"work_permit_student_general\",\n",
        "    \"work-and-education-data\",\n",
        "    \"vancouver_transit_qa_pairs\",\n",
        "    \"permanent_residence_student_general\",\n",
        "    \"data-with-sources\"\n",
        "]\n",
        "\n",
        "all_texts = []\n",
        "\n",
        "for file in file_names:\n",
        "    path = f'./sample_data/{file}.csv'\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        df.columns = df.columns.str.lower()\n",
        "\n",
        "        if 'question' in df.columns and 'answer' in df.columns:\n",
        "            df = df.drop_duplicates(subset=['question'])\n",
        "            df['text'] = df['question'].fillna('') + ' ' + df['answer'].fillna('')\n",
        "        elif 'theme' in df.columns and 'content' in df.columns:\n",
        "            df = df.drop_duplicates(subset=['content'])\n",
        "            df['text'] = df['theme'].fillna('') + ' ' + df['content'].fillna('')\n",
        "        else:\n",
        "            print(f\"no text columns in {file}\")\n",
        "            continue\n",
        "        all_texts.extend(df['text'].tolist())\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP8skJRg8LZ_",
        "outputId": "d7225af6-0281-478b-c20c-c3f6489393e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.12)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.21.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.46.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.31.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.29.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "# forgot one dependency\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5NPcS-__W2F"
      },
      "source": [
        "Set Embedding Model, and Chroma Client to Interact w Vector Database and Create Collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCNO3e62K-G3",
        "outputId": "9b2271e0-cb60-4b5d-f972-758639f259de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.4)\n"
          ]
        }
      ],
      "source": [
        "#!pip install -U numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKdxYOca7KfJ",
        "outputId": "34564ef5-0260-4b54-c037-909ffc55f84b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successfully added 1053 documents to Chroma DB.\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "import chromadb\n",
        "import uuid\n",
        "import pandas as pd\n",
        "#from fuzzywuzzy import fuzz\n",
        "\n",
        "# pt model for geenrating embeddings used pretty often\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "# persistent client to interact w chroma vector store\n",
        "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "# create collections for each data (for testing rn)\n",
        "collection = client.get_or_create_collection(name=\"combined_docs\")\n",
        "\n",
        "# seems like better results if we remove duplicates and very similar data\n",
        "data = pd.DataFrame({\"text\": all_texts})\n",
        "data = data.drop_duplicates()\n",
        "all_texts = data[\"text\"].tolist()\n",
        "\n",
        "'''\n",
        "def remove_fuzzy_duplicates(texts, threshold=90):\n",
        "    unique_texts = []\n",
        "    for text in texts:\n",
        "        if not any(fuzz.ratio(text, existing_text) > threshold for existing_text in unique_texts):\n",
        "            unique_texts.append(text)\n",
        "    return unique_texts\n",
        "\n",
        "all_texts = remove_fuzzy_duplicates(all_texts, threshold=90)\n",
        "'''\n",
        "\n",
        "print(f\"successfully added {len(all_texts)} documents to Chroma DB.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOEGkLgl_e2Z"
      },
      "source": [
        "Function to add data to collection by embedding them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "9lN1Q5d_8jZt"
      },
      "outputs": [],
      "source": [
        "def add_data_to_collection_batch(collection, texts, batch_size=3):\n",
        "    for idx in range(0, len(texts), batch_size):\n",
        "        try:\n",
        "            batch_texts = texts[idx: idx + batch_size]\n",
        "\n",
        "            embeddings = embedding_model.embed_documents(batch_texts)\n",
        "\n",
        "            batch_ids = [str(uuid.uuid4()) for _ in batch_texts]\n",
        "\n",
        "            collection.add(\n",
        "                ids=batch_ids,\n",
        "                embeddings=embeddings,\n",
        "                documents=batch_texts\n",
        "            )\n",
        "            print(f\"successfully added {len(batch_texts)} documents (Batch {idx}-{idx + batch_size - 1})\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing batch starting at index {idx}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JEgUfbRMg5e",
        "outputId": "d844addb-edb2-4645-b912-f685ccd8dd45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added 3 documents (Batch 0-2)\n",
            "Successfully added 3 documents (Batch 3-5)\n",
            "Successfully added 3 documents (Batch 6-8)\n",
            "Successfully added 3 documents (Batch 9-11)\n",
            "Successfully added 3 documents (Batch 12-14)\n",
            "Successfully added 3 documents (Batch 15-17)\n",
            "Successfully added 3 documents (Batch 18-20)\n",
            "Successfully added 3 documents (Batch 21-23)\n",
            "Successfully added 3 documents (Batch 24-26)\n",
            "Successfully added 3 documents (Batch 27-29)\n",
            "Successfully added 3 documents (Batch 30-32)\n",
            "Successfully added 3 documents (Batch 33-35)\n",
            "Successfully added 3 documents (Batch 36-38)\n",
            "Successfully added 3 documents (Batch 39-41)\n",
            "Successfully added 3 documents (Batch 42-44)\n",
            "Successfully added 3 documents (Batch 45-47)\n",
            "Successfully added 3 documents (Batch 48-50)\n",
            "Successfully added 3 documents (Batch 51-53)\n",
            "Successfully added 3 documents (Batch 54-56)\n",
            "Successfully added 3 documents (Batch 57-59)\n",
            "Successfully added 3 documents (Batch 60-62)\n",
            "Successfully added 3 documents (Batch 63-65)\n",
            "Successfully added 3 documents (Batch 66-68)\n",
            "Successfully added 3 documents (Batch 69-71)\n",
            "Successfully added 3 documents (Batch 72-74)\n",
            "Successfully added 3 documents (Batch 75-77)\n",
            "Successfully added 3 documents (Batch 78-80)\n",
            "Successfully added 3 documents (Batch 81-83)\n",
            "Successfully added 3 documents (Batch 84-86)\n",
            "Successfully added 3 documents (Batch 87-89)\n",
            "Successfully added 3 documents (Batch 90-92)\n",
            "Successfully added 3 documents (Batch 93-95)\n",
            "Successfully added 3 documents (Batch 96-98)\n",
            "Successfully added 3 documents (Batch 99-101)\n",
            "Successfully added 3 documents (Batch 102-104)\n",
            "Successfully added 3 documents (Batch 105-107)\n",
            "Successfully added 3 documents (Batch 108-110)\n",
            "Successfully added 3 documents (Batch 111-113)\n",
            "Successfully added 3 documents (Batch 114-116)\n",
            "Successfully added 3 documents (Batch 117-119)\n",
            "Successfully added 3 documents (Batch 120-122)\n",
            "Successfully added 3 documents (Batch 123-125)\n",
            "Successfully added 3 documents (Batch 126-128)\n",
            "Successfully added 3 documents (Batch 129-131)\n",
            "Successfully added 3 documents (Batch 132-134)\n",
            "Successfully added 3 documents (Batch 135-137)\n",
            "Successfully added 3 documents (Batch 138-140)\n",
            "Successfully added 3 documents (Batch 141-143)\n",
            "Successfully added 3 documents (Batch 144-146)\n",
            "Successfully added 3 documents (Batch 147-149)\n",
            "Successfully added 3 documents (Batch 150-152)\n",
            "Successfully added 3 documents (Batch 153-155)\n",
            "Successfully added 3 documents (Batch 156-158)\n",
            "Successfully added 3 documents (Batch 159-161)\n",
            "Successfully added 3 documents (Batch 162-164)\n",
            "Successfully added 3 documents (Batch 165-167)\n",
            "Successfully added 3 documents (Batch 168-170)\n",
            "Successfully added 3 documents (Batch 171-173)\n",
            "Successfully added 3 documents (Batch 174-176)\n",
            "Successfully added 3 documents (Batch 177-179)\n",
            "Successfully added 3 documents (Batch 180-182)\n",
            "Successfully added 3 documents (Batch 183-185)\n",
            "Successfully added 3 documents (Batch 186-188)\n",
            "Successfully added 3 documents (Batch 189-191)\n",
            "Successfully added 3 documents (Batch 192-194)\n",
            "Successfully added 3 documents (Batch 195-197)\n",
            "Successfully added 3 documents (Batch 198-200)\n",
            "Successfully added 3 documents (Batch 201-203)\n",
            "Successfully added 3 documents (Batch 204-206)\n",
            "Successfully added 3 documents (Batch 207-209)\n",
            "Successfully added 3 documents (Batch 210-212)\n",
            "Successfully added 3 documents (Batch 213-215)\n",
            "Successfully added 3 documents (Batch 216-218)\n",
            "Successfully added 3 documents (Batch 219-221)\n",
            "Successfully added 3 documents (Batch 222-224)\n",
            "Successfully added 3 documents (Batch 225-227)\n",
            "Successfully added 3 documents (Batch 228-230)\n",
            "Successfully added 3 documents (Batch 231-233)\n",
            "Successfully added 3 documents (Batch 234-236)\n",
            "Successfully added 3 documents (Batch 237-239)\n",
            "Successfully added 3 documents (Batch 240-242)\n",
            "Successfully added 3 documents (Batch 243-245)\n",
            "Successfully added 3 documents (Batch 246-248)\n",
            "Successfully added 3 documents (Batch 249-251)\n",
            "Successfully added 3 documents (Batch 252-254)\n",
            "Successfully added 3 documents (Batch 255-257)\n",
            "Successfully added 3 documents (Batch 258-260)\n",
            "Successfully added 3 documents (Batch 261-263)\n",
            "Successfully added 3 documents (Batch 264-266)\n",
            "Successfully added 3 documents (Batch 267-269)\n",
            "Successfully added 3 documents (Batch 270-272)\n",
            "Successfully added 3 documents (Batch 273-275)\n",
            "Successfully added 3 documents (Batch 276-278)\n",
            "Successfully added 3 documents (Batch 279-281)\n",
            "Successfully added 3 documents (Batch 282-284)\n",
            "Successfully added 3 documents (Batch 285-287)\n",
            "Successfully added 3 documents (Batch 288-290)\n",
            "Successfully added 3 documents (Batch 291-293)\n",
            "Successfully added 3 documents (Batch 294-296)\n",
            "Successfully added 3 documents (Batch 297-299)\n",
            "Successfully added 3 documents (Batch 300-302)\n",
            "Successfully added 3 documents (Batch 303-305)\n",
            "Successfully added 3 documents (Batch 306-308)\n",
            "Successfully added 3 documents (Batch 309-311)\n",
            "Successfully added 3 documents (Batch 312-314)\n",
            "Successfully added 3 documents (Batch 315-317)\n",
            "Successfully added 3 documents (Batch 318-320)\n",
            "Successfully added 3 documents (Batch 321-323)\n",
            "Successfully added 3 documents (Batch 324-326)\n",
            "Successfully added 3 documents (Batch 327-329)\n",
            "Successfully added 3 documents (Batch 330-332)\n",
            "Successfully added 3 documents (Batch 333-335)\n",
            "Successfully added 3 documents (Batch 336-338)\n",
            "Successfully added 3 documents (Batch 339-341)\n",
            "Successfully added 3 documents (Batch 342-344)\n",
            "Successfully added 3 documents (Batch 345-347)\n",
            "Successfully added 3 documents (Batch 348-350)\n",
            "Successfully added 3 documents (Batch 351-353)\n",
            "Successfully added 3 documents (Batch 354-356)\n",
            "Successfully added 3 documents (Batch 357-359)\n",
            "Successfully added 3 documents (Batch 360-362)\n",
            "Successfully added 3 documents (Batch 363-365)\n",
            "Successfully added 3 documents (Batch 366-368)\n",
            "Successfully added 3 documents (Batch 369-371)\n",
            "Successfully added 3 documents (Batch 372-374)\n",
            "Successfully added 3 documents (Batch 375-377)\n",
            "Successfully added 3 documents (Batch 378-380)\n",
            "Successfully added 3 documents (Batch 381-383)\n",
            "Successfully added 3 documents (Batch 384-386)\n",
            "Successfully added 3 documents (Batch 387-389)\n",
            "Successfully added 3 documents (Batch 390-392)\n",
            "Successfully added 3 documents (Batch 393-395)\n",
            "Successfully added 3 documents (Batch 396-398)\n",
            "Successfully added 3 documents (Batch 399-401)\n",
            "Successfully added 3 documents (Batch 402-404)\n",
            "Successfully added 3 documents (Batch 405-407)\n",
            "Successfully added 3 documents (Batch 408-410)\n",
            "Successfully added 3 documents (Batch 411-413)\n",
            "Successfully added 3 documents (Batch 414-416)\n",
            "Successfully added 3 documents (Batch 417-419)\n",
            "Successfully added 3 documents (Batch 420-422)\n",
            "Successfully added 3 documents (Batch 423-425)\n",
            "Successfully added 3 documents (Batch 426-428)\n",
            "Successfully added 3 documents (Batch 429-431)\n",
            "Successfully added 3 documents (Batch 432-434)\n",
            "Successfully added 3 documents (Batch 435-437)\n",
            "Successfully added 3 documents (Batch 438-440)\n",
            "Successfully added 3 documents (Batch 441-443)\n",
            "Successfully added 3 documents (Batch 444-446)\n",
            "Successfully added 3 documents (Batch 447-449)\n",
            "Successfully added 3 documents (Batch 450-452)\n",
            "Successfully added 3 documents (Batch 453-455)\n",
            "Successfully added 3 documents (Batch 456-458)\n",
            "Successfully added 3 documents (Batch 459-461)\n",
            "Successfully added 3 documents (Batch 462-464)\n",
            "Successfully added 3 documents (Batch 465-467)\n",
            "Successfully added 3 documents (Batch 468-470)\n",
            "Successfully added 3 documents (Batch 471-473)\n",
            "Successfully added 3 documents (Batch 474-476)\n",
            "Successfully added 3 documents (Batch 477-479)\n",
            "Successfully added 3 documents (Batch 480-482)\n",
            "Successfully added 3 documents (Batch 483-485)\n",
            "Successfully added 3 documents (Batch 486-488)\n",
            "Successfully added 3 documents (Batch 489-491)\n",
            "Successfully added 3 documents (Batch 492-494)\n",
            "Successfully added 3 documents (Batch 495-497)\n",
            "Successfully added 3 documents (Batch 498-500)\n",
            "Successfully added 3 documents (Batch 501-503)\n",
            "Successfully added 3 documents (Batch 504-506)\n",
            "Successfully added 3 documents (Batch 507-509)\n",
            "Successfully added 3 documents (Batch 510-512)\n",
            "Successfully added 3 documents (Batch 513-515)\n",
            "Successfully added 3 documents (Batch 516-518)\n",
            "Successfully added 3 documents (Batch 519-521)\n",
            "Successfully added 3 documents (Batch 522-524)\n",
            "Successfully added 3 documents (Batch 525-527)\n",
            "Successfully added 3 documents (Batch 528-530)\n",
            "Successfully added 3 documents (Batch 531-533)\n",
            "Successfully added 3 documents (Batch 534-536)\n",
            "Successfully added 3 documents (Batch 537-539)\n",
            "Successfully added 3 documents (Batch 540-542)\n",
            "Successfully added 3 documents (Batch 543-545)\n",
            "Successfully added 3 documents (Batch 546-548)\n",
            "Successfully added 3 documents (Batch 549-551)\n",
            "Successfully added 3 documents (Batch 552-554)\n",
            "Successfully added 3 documents (Batch 555-557)\n",
            "Successfully added 3 documents (Batch 558-560)\n",
            "Successfully added 3 documents (Batch 561-563)\n",
            "Successfully added 3 documents (Batch 564-566)\n",
            "Successfully added 3 documents (Batch 567-569)\n",
            "Successfully added 3 documents (Batch 570-572)\n",
            "Successfully added 3 documents (Batch 573-575)\n",
            "Successfully added 3 documents (Batch 576-578)\n",
            "Successfully added 3 documents (Batch 579-581)\n",
            "Successfully added 3 documents (Batch 582-584)\n",
            "Successfully added 3 documents (Batch 585-587)\n",
            "Successfully added 3 documents (Batch 588-590)\n",
            "Successfully added 3 documents (Batch 591-593)\n",
            "Successfully added 3 documents (Batch 594-596)\n",
            "Successfully added 3 documents (Batch 597-599)\n",
            "Successfully added 3 documents (Batch 600-602)\n",
            "Successfully added 3 documents (Batch 603-605)\n",
            "Successfully added 3 documents (Batch 606-608)\n",
            "Successfully added 3 documents (Batch 609-611)\n",
            "Successfully added 3 documents (Batch 612-614)\n",
            "Successfully added 3 documents (Batch 615-617)\n",
            "Successfully added 3 documents (Batch 618-620)\n",
            "Successfully added 3 documents (Batch 621-623)\n",
            "Successfully added 3 documents (Batch 624-626)\n",
            "Successfully added 3 documents (Batch 627-629)\n",
            "Successfully added 3 documents (Batch 630-632)\n",
            "Successfully added 3 documents (Batch 633-635)\n",
            "Successfully added 3 documents (Batch 636-638)\n",
            "Successfully added 3 documents (Batch 639-641)\n",
            "Successfully added 3 documents (Batch 642-644)\n",
            "Successfully added 3 documents (Batch 645-647)\n",
            "Successfully added 3 documents (Batch 648-650)\n",
            "Successfully added 3 documents (Batch 651-653)\n",
            "Successfully added 3 documents (Batch 654-656)\n",
            "Successfully added 3 documents (Batch 657-659)\n",
            "Successfully added 3 documents (Batch 660-662)\n",
            "Successfully added 3 documents (Batch 663-665)\n",
            "Successfully added 3 documents (Batch 666-668)\n",
            "Successfully added 3 documents (Batch 669-671)\n",
            "Successfully added 3 documents (Batch 672-674)\n",
            "Successfully added 3 documents (Batch 675-677)\n",
            "Successfully added 3 documents (Batch 678-680)\n",
            "Successfully added 3 documents (Batch 681-683)\n",
            "Successfully added 3 documents (Batch 684-686)\n",
            "Successfully added 3 documents (Batch 687-689)\n",
            "Successfully added 3 documents (Batch 690-692)\n",
            "Successfully added 3 documents (Batch 693-695)\n",
            "Successfully added 3 documents (Batch 696-698)\n",
            "Successfully added 3 documents (Batch 699-701)\n",
            "Successfully added 3 documents (Batch 702-704)\n",
            "Successfully added 3 documents (Batch 705-707)\n",
            "Successfully added 3 documents (Batch 708-710)\n",
            "Successfully added 3 documents (Batch 711-713)\n",
            "Successfully added 3 documents (Batch 714-716)\n",
            "Successfully added 3 documents (Batch 717-719)\n",
            "Successfully added 3 documents (Batch 720-722)\n",
            "Successfully added 3 documents (Batch 723-725)\n",
            "Successfully added 3 documents (Batch 726-728)\n",
            "Successfully added 3 documents (Batch 729-731)\n",
            "Successfully added 3 documents (Batch 732-734)\n",
            "Successfully added 3 documents (Batch 735-737)\n",
            "Successfully added 3 documents (Batch 738-740)\n",
            "Successfully added 3 documents (Batch 741-743)\n",
            "Successfully added 3 documents (Batch 744-746)\n",
            "Successfully added 3 documents (Batch 747-749)\n",
            "Successfully added 3 documents (Batch 750-752)\n",
            "Successfully added 3 documents (Batch 753-755)\n",
            "Successfully added 3 documents (Batch 756-758)\n",
            "Successfully added 3 documents (Batch 759-761)\n",
            "Successfully added 3 documents (Batch 762-764)\n",
            "Successfully added 3 documents (Batch 765-767)\n",
            "Successfully added 3 documents (Batch 768-770)\n",
            "Successfully added 3 documents (Batch 771-773)\n",
            "Successfully added 3 documents (Batch 774-776)\n",
            "Successfully added 3 documents (Batch 777-779)\n",
            "Successfully added 3 documents (Batch 780-782)\n",
            "Successfully added 3 documents (Batch 783-785)\n",
            "Successfully added 3 documents (Batch 786-788)\n",
            "Successfully added 3 documents (Batch 789-791)\n",
            "Successfully added 3 documents (Batch 792-794)\n",
            "Successfully added 3 documents (Batch 795-797)\n",
            "Successfully added 3 documents (Batch 798-800)\n",
            "Successfully added 3 documents (Batch 801-803)\n",
            "Successfully added 3 documents (Batch 804-806)\n",
            "Successfully added 3 documents (Batch 807-809)\n",
            "Successfully added 3 documents (Batch 810-812)\n",
            "Successfully added 3 documents (Batch 813-815)\n",
            "Successfully added 3 documents (Batch 816-818)\n",
            "Successfully added 3 documents (Batch 819-821)\n",
            "Successfully added 3 documents (Batch 822-824)\n",
            "Successfully added 3 documents (Batch 825-827)\n",
            "Successfully added 3 documents (Batch 828-830)\n",
            "Successfully added 3 documents (Batch 831-833)\n",
            "Successfully added 3 documents (Batch 834-836)\n",
            "Successfully added 3 documents (Batch 837-839)\n",
            "Successfully added 3 documents (Batch 840-842)\n",
            "Successfully added 3 documents (Batch 843-845)\n",
            "Successfully added 3 documents (Batch 846-848)\n",
            "Successfully added 3 documents (Batch 849-851)\n",
            "Successfully added 3 documents (Batch 852-854)\n",
            "Successfully added 3 documents (Batch 855-857)\n",
            "Successfully added 3 documents (Batch 858-860)\n",
            "Successfully added 3 documents (Batch 861-863)\n",
            "Successfully added 3 documents (Batch 864-866)\n",
            "Successfully added 3 documents (Batch 867-869)\n",
            "Successfully added 3 documents (Batch 870-872)\n",
            "Successfully added 3 documents (Batch 873-875)\n",
            "Successfully added 3 documents (Batch 876-878)\n",
            "Successfully added 3 documents (Batch 879-881)\n",
            "Successfully added 3 documents (Batch 882-884)\n",
            "Successfully added 3 documents (Batch 885-887)\n",
            "Successfully added 3 documents (Batch 888-890)\n",
            "Successfully added 3 documents (Batch 891-893)\n",
            "Successfully added 3 documents (Batch 894-896)\n",
            "Successfully added 3 documents (Batch 897-899)\n",
            "Successfully added 3 documents (Batch 900-902)\n",
            "Successfully added 3 documents (Batch 903-905)\n",
            "Successfully added 3 documents (Batch 906-908)\n",
            "Successfully added 3 documents (Batch 909-911)\n",
            "Successfully added 3 documents (Batch 912-914)\n",
            "Successfully added 3 documents (Batch 915-917)\n",
            "Successfully added 3 documents (Batch 918-920)\n",
            "Successfully added 3 documents (Batch 921-923)\n",
            "Successfully added 3 documents (Batch 924-926)\n",
            "Successfully added 3 documents (Batch 927-929)\n",
            "Successfully added 3 documents (Batch 930-932)\n",
            "Successfully added 3 documents (Batch 933-935)\n",
            "Successfully added 3 documents (Batch 936-938)\n",
            "Successfully added 3 documents (Batch 939-941)\n",
            "Successfully added 3 documents (Batch 942-944)\n",
            "Successfully added 3 documents (Batch 945-947)\n",
            "Successfully added 3 documents (Batch 948-950)\n",
            "Successfully added 3 documents (Batch 951-953)\n",
            "Successfully added 3 documents (Batch 954-956)\n",
            "Successfully added 3 documents (Batch 957-959)\n",
            "Successfully added 3 documents (Batch 960-962)\n",
            "Successfully added 3 documents (Batch 963-965)\n",
            "Successfully added 3 documents (Batch 966-968)\n",
            "Successfully added 3 documents (Batch 969-971)\n",
            "Successfully added 3 documents (Batch 972-974)\n",
            "Successfully added 3 documents (Batch 975-977)\n",
            "Successfully added 3 documents (Batch 978-980)\n",
            "Successfully added 3 documents (Batch 981-983)\n",
            "Successfully added 3 documents (Batch 984-986)\n",
            "Successfully added 3 documents (Batch 987-989)\n",
            "Successfully added 3 documents (Batch 990-992)\n",
            "Successfully added 3 documents (Batch 993-995)\n",
            "Successfully added 3 documents (Batch 996-998)\n",
            "Successfully added 3 documents (Batch 999-1001)\n",
            "Successfully added 3 documents (Batch 1002-1004)\n",
            "Successfully added 3 documents (Batch 1005-1007)\n",
            "Successfully added 3 documents (Batch 1008-1010)\n",
            "Successfully added 3 documents (Batch 1011-1013)\n",
            "Successfully added 3 documents (Batch 1014-1016)\n",
            "Successfully added 3 documents (Batch 1017-1019)\n",
            "Successfully added 3 documents (Batch 1020-1022)\n",
            "Successfully added 3 documents (Batch 1023-1025)\n",
            "Successfully added 3 documents (Batch 1026-1028)\n",
            "Successfully added 3 documents (Batch 1029-1031)\n",
            "Successfully added 3 documents (Batch 1032-1034)\n",
            "Successfully added 3 documents (Batch 1035-1037)\n",
            "Successfully added 3 documents (Batch 1038-1040)\n",
            "Successfully added 3 documents (Batch 1041-1043)\n",
            "Successfully added 3 documents (Batch 1044-1046)\n",
            "Successfully added 3 documents (Batch 1047-1049)\n",
            "Successfully added 3 documents (Batch 1050-1052)\n",
            "successfully added 1053 documents to the Chroma collection.\n"
          ]
        }
      ],
      "source": [
        "add_data_to_collection_batch(collection, all_texts)\n",
        "print(f\"successfully added {len(all_texts)} documents to the Chroma collection.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn2LQiJq_k9t"
      },
      "source": [
        "Function to now match for releveant document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TEulNQZw8mDo"
      },
      "outputs": [],
      "source": [
        "def get_relevant_documents(query, n_results=3):\n",
        "    try:\n",
        "        query_embeddings = embedding_model.embed_documents([query])[0]\n",
        "\n",
        "        results = collection.query(query_embeddings=[query_embeddings], n_results=n_results)\n",
        "        print(f\"Query Results: {results}\")\n",
        "\n",
        "        return results['documents'][0] if results['documents'] else []\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV_h8UJa_pGj"
      },
      "source": [
        "Generate Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "EMTYliNl8onj"
      },
      "outputs": [],
      "source": [
        "def generate_answer(query):\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\")\n",
        "    base_output = model.generate(inputs[\"input_ids\"], max_length=150, temperature=0.1)\n",
        "    response_before_rag = tokenizer.decode(base_output[0], skip_special_tokens=True)\n",
        "\n",
        "    relevant_documents = get_relevant_documents(query)\n",
        "    if not relevant_documents:\n",
        "        return {\n",
        "            \"Before RAG Response\": response_before_rag,\n",
        "            \"After RAG Response\": \"Sorry, no relevant documents found.\"\n",
        "        }\n",
        "\n",
        "    relevant_texts = \"\\n\\n\".join([doc for doc in relevant_documents])\n",
        "    rag_prompt = f\"\"\"\n",
        "    You are a helpful assistant for international students. Here are relevant documents:\n",
        "\n",
        "    {relevant_texts}\n",
        "\n",
        "    Please respond to the following question based on the documents above. Be conversational but concise:\n",
        "\n",
        "    Question: {query}\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    rag_inputs = tokenizer(rag_prompt, return_tensors=\"pt\")\n",
        "    rag_output = model.generate(rag_inputs[\"input_ids\"], max_length=500, temperature=0.1)\n",
        "    response_after_rag = tokenizer.decode(rag_output[0], skip_special_tokens=True)\n",
        "\n",
        "    return {\n",
        "        \"Before RAG Response\": response_before_rag,\n",
        "        \"After RAG Response\": response_after_rag\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxtEFTiK_q8E"
      },
      "source": [
        "Example Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EVDilNoM8sU8",
        "outputId": "7caa2fec-3bb2-4f84-9089-f1476855bc63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Results: {'ids': [['a9e9b5f4-01e3-469b-b7c1-768022665ff5', 'd8a7253f-3659-448c-bb0c-b8489df8af47', '30a5a828-0efc-428a-989f-836ffc0c6d06']], 'embeddings': None, 'documents': [['Study Permit Application Process When you apply online, your personalized checklist will include the Application to Change Conditions, Extend my Stay or Remain in Canada as a Student [IMM 5709]. On that form, check the box to Apply for a study permit for the first time or extend my study permit and fill out the rest of the required fields.', 'Study Permit Application Process Most foreign nationals already in Canada can no longer apply for a study permit at a port of entry. You must apply online for', 'Extending a Study Permit If you want to keep studying in Canada, you must']], 'uris': None, 'data': None, 'metadatas': [[None, None, None]], 'distances': [[0.3383488655090332, 0.40008115768432617, 0.40086132287979126]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Test Query 1: How do I apply for a study permit in Canada?\n",
            "==================================================\n",
            "Response Before RAG:\n",
            " How do I apply for a study permit in Canada? The application process typically involves several steps, which I'll outline below.\n",
            "\n",
            "## Step 1: Determine Your Eligibility\n",
            "To apply for a study permit in Canada, you must meet certain eligibility criteria. These include being a permanent resident of Canada, having a valid passport, and having sufficient funds to support yourself during your stay in Canada.\n",
            "\n",
            "## Step 2: Choose the Correct Application Type\n",
            "There are two main types of study permits: a study permit for a specific program (e.g., a bachelor's degree) and a study permit for a general program (e.g., a master's degree). You must choose the correct application type based on your program of study.\n",
            "\n",
            "## Step 3\n",
            "\n",
            "Response After RAG:\n",
            " \n",
            "    You are a helpful assistant for international students. Here are relevant documents:\n",
            "\n",
            "    Study Permit Application Process When you apply online, your personalized checklist will include the Application to Change Conditions, Extend my Stay or Remain in Canada as a Student [IMM 5709]. On that form, check the box to Apply for a study permit for the first time or extend my study permit and fill out the rest of the required fields.\n",
            "\n",
            "Study Permit Application Process Most foreign nationals already in Canada can no longer apply for a study permit at a port of entry. You must apply online for\n",
            "\n",
            "Extending a Study Permit If you want to keep studying in Canada, you must\n",
            "\n",
            "    Please respond to the following question based on the documents above. Be conversational but concise:\n",
            "\n",
            "    Question: How do I apply for a study permit in Canada?\n",
            "\n",
            "    Answer:\n",
            "     To apply for a study permit in Canada, you can apply online through the Immigration, Refugees and Citizenship Canada (IRCC) website. You will need to provide personal and educational information, as well as proof of financial support and health insurance. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial support and health insurance, as well as a copy of your passport. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial support and health insurance, as well as a copy of your passport. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial support and health insurance, as well as a copy of your passport. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial support and health insurance, as well as a copy of your passport. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial support and health insurance, as well as a copy of your passport. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial support and health insurance, as well as a copy of your passport. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial\n",
            "==================================================\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Results: {'ids': [['f49f0ece-d747-4594-a770-721355511f00', '0e1017e4-90c6-49d3-be3a-7a9428aeeafb', '22006685-c985-4364-8d8d-8e6d8268c1fb']], 'embeddings': None, 'documents': [[\"Work Permits for International Students If you're able to work during your studies, it'll say so in the conditions on your study permit.\", \"Work Permits for International Students If you're able to work during your studies, it'll say so in the conditions on your study permit.\", \"Work Permits for International Students If you're able to work during your studies, it'll say so in the conditions on your study permit.\"]], 'uris': None, 'data': None, 'metadatas': [[None, None, None]], 'distances': [[0.5540599822998047, 0.5540599822998047, 0.554060161113739]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Test Query 2: Can I work while studying on a student visa?\n",
            "==================================================\n",
            "Response Before RAG:\n",
            " Can I work while studying on a student visa? Working while studying on a student visa is a common practice, but it's essential to understand the rules and regulations surrounding it.\n",
            "\n",
            "**Understanding the rules:**\n",
            "\n",
            "*   **Employment and student status:** You must be a student and not an employee to work while studying on a student visa.\n",
            "*   **Work hours and duration:** You can work up to 20 hours per week, and you must not exceed 40 hours per month.\n",
            "*   **Employment contract:** You must have a written employment contract with your employer, which includes the terms of your employment, working hours, and salary.\n",
            "*   **Tax and benefits:** You must pay taxes on your earnings and benefits, and you\n",
            "\n",
            "Response After RAG:\n",
            " \n",
            "    You are a helpful assistant for international students. Here are relevant documents:\n",
            "\n",
            "    Work Permits for International Students If you're able to work during your studies, it'll say so in the conditions on your study permit.\n",
            "\n",
            "Work Permits for International Students If you're able to work during your studies, it'll say so in the conditions on your study permit.\n",
            "\n",
            "Work Permits for International Students If you're able to work during your studies, it'll say so in the conditions on your study permit.\n",
            "\n",
            "    Please respond to the following question based on the documents above. Be conversational but concise:\n",
            "\n",
            "    Question: Can I work while studying on a student visa?\n",
            "\n",
            "    Answer:\n",
            "     Yes, you can work while studying on a student visa. In fact, many students on a student visa are able to work part-time to support themselves financially. However, you'll need to check the specific conditions on your study permit to see if you're eligible to work. Some student visas, like the F-1 visa, have specific requirements for work permits, while others, like the J-1 visa, have different rules. It's always a good idea to check with the relevant authorities or your university to confirm your eligibility.\n",
            "==================================================\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Results: {'ids': [['13b81354-0ec4-4fda-a068-7d9496a1ee48', '267bbdd2-8c18-4878-af02-bb4069d92172', 'c6082afc-c3b5-466e-9ce1-02a40b1b3e29']], 'embeddings': None, 'documents': [['Study Permit Expiration and Renewal What happens when your permit expires\\nYou lose your student status in Canada if any of the following applies to you:', 'Extending a Study Permit What happens when your permit expires\\nYou lose your student status in Canada if any of the following applies to you:', 'Extending a Study Permit What happens when your permit expires\\nYou lose your student status in Canada if any of the following applies to you:']], 'uris': None, 'data': None, 'metadatas': [[None, None, None]], 'distances': [[0.38881877064704895, 0.43466609716415405, 0.43466609716415405]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Test Query 3: What happens if my study permit expires before I finish my program?\n",
            "==================================================\n",
            "Response Before RAG:\n",
            " What happens if my study permit expires before I finish my program? Can I still enter Canada?\n",
            "If your study permit expires before you finish your program, you may be eligible to apply for a new study permit. However, there are some conditions and requirements you need to meet.\n",
            "\n",
            "Here are the steps to follow:\n",
            "\n",
            "1. **Check if your study permit has expired**: You can check the status of your study permit online through the Immigration, Refugees and Citizenship Canada (IRCC) website.\n",
            "2. **Contact the IRCC**: If your study permit has expired, contact the IRCC to inquire about the next steps. They may ask you to provide documentation, such as proof of payment for the application fee or proof of completion of your program.\n",
            "\n",
            "\n",
            "Response After RAG:\n",
            " \n",
            "    You are a helpful assistant for international students. Here are relevant documents:\n",
            "\n",
            "    Study Permit Expiration and Renewal What happens when your permit expires\n",
            "You lose your student status in Canada if any of the following applies to you:\n",
            "\n",
            "Extending a Study Permit What happens when your permit expires\n",
            "You lose your student status in Canada if any of the following applies to you:\n",
            "\n",
            "Extending a Study Permit What happens when your permit expires\n",
            "You lose your student status in Canada if any of the following applies to you:\n",
            "\n",
            "    Please respond to the following question based on the documents above. Be conversational but concise:\n",
            "\n",
            "    Question: What happens if my study permit expires before I finish my program?\n",
            "\n",
            "    Answer:\n",
            "     If your study permit expires before you finish your program, you will lose your student status in Canada. This means you will no longer be eligible to study in Canada and will need to apply for a new study permit. You may also need to apply for a work permit if you want to work in Canada.\n",
            "==================================================\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Results: {'ids': [['b93fb3dc-8910-4cbb-858b-39291370569c', '8a55474b-3669-47fb-920d-6e8d4fa73cf6', 'c6ac72f1-0967-458d-80f5-547120bf2138']], 'embeddings': None, 'documents': [[\"Extending a Study Permit If your study situation changes\\nIf you weren't eligible to work off campus, but your study situation has now changed, you may be able to change the conditions of your study permit.\", \"Study Permit Application Process If your study situation changes\\nIf you weren't eligible to work off campus, but your study situation has now changed, you may be able to change the conditions of your study permit.\", 'Extending a Study Permit keep studying until your current permit expires or\\ntransfer to another DLI\\nIf you want to extend your study permit, you’ll need to enroll at a school with DLI status.']], 'uris': None, 'data': None, 'metadatas': [[None, None, None]], 'distances': [[0.6665720343589783, 0.6875311136245728, 0.7013002634048462]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-4019d776cd8e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_query\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-1013fe83b582>\u001b[0m in \u001b[0;36mgenerate_answer\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mrag_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrag_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mrag_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrag_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mresponse_after_rag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrag_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2048\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynced_gpus\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    998\u001b[0m                 )\n\u001b[1;32m    999\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1001\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "test_queries = [\n",
        "    \"How do I apply for a study permit in Canada?\",\n",
        "    \"Can I work while studying on a student visa?\",\n",
        "    \"What happens if my study permit expires before I finish my program?\",\n",
        "    \"Do I need a new study permit if I change schools?\",\n",
        "    \"How long does it take to process a Canadian study permit?\",\n",
        "    \"Am I allowed to work off-campus as an international student?\",\n",
        "    \"How many hours can I work while studying in Canada?\",\n",
        "    \"What documents do I need to apply for a co-op work permit?\",\n",
        "    \"Can I work in Canada after I graduate?\",\n",
        "    \"What is a Post-Graduation Work Permit (PGWP) and how do I apply?\",\n",
        "    \"How do I apply for MSP (Medical Services Plan) in British Columbia?\",\n",
        "    \"Is MSP mandatory for international students?\",\n",
        "    \"What healthcare services are covered under MSP?\",\n",
        "    \"What should I do if I get sick and don’t have insurance yet?\",\n",
        "    \"Can I use private health insurance instead of MSP?\",\n",
        "    \"What are my options for student housing in Vancouver?\",\n",
        "    \"How much does rent typically cost for international students?\",\n",
        "    \"What should I check before signing a lease in Canada?\",\n",
        "    \"Are there any student discounts for accommodation?\",\n",
        "    \"How can I find a roommate in Canada?\",\n",
        "    \"How do I open a bank account as an international student?\",\n",
        "    \"What documents do I need to get a student bank account?\",\n",
        "    \"Can I get a credit card as an international student?\",\n",
        "    \"How do I send money to my home country from Canada?\",\n",
        "    \"What scholarships are available for international students?\",\n",
        "    \"How does the Compass Card work for transit in Vancouver?\",\n",
        "    \"Am I eligible for a U-Pass as an international student?\",\n",
        "    \"What is the best way to get around Vancouver on a budget?\",\n",
        "    \"Where can I find the bus and SkyTrain schedules?\",\n",
        "    \"Are there student discounts for public transportation?\",\n",
        "    \"Can I apply for permanent residence after graduating?\",\n",
        "    \"What is the Canadian Experience Class (CEC) immigration program?\",\n",
        "    \"How can I improve my chances of getting permanent residence?\",\n",
        "    \"What are the eligibility requirements for Express Entry?\",\n",
        "    \"Does having a Canadian degree help with PR applications?\"\n",
        "]\n",
        "\n",
        "for idx, user_query in enumerate(test_queries, start=1):\n",
        "    responses = generate_answer(user_query)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Test Query {idx}: {user_query}\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Response Before RAG:\\n\", responses[\"Before RAG Response\"])\n",
        "    print(\"\\nResponse After RAG:\\n\", responses[\"After RAG Response\"])\n",
        "    print(\"=\"*50 + \"\\n\\n\")\n",
        "\n",
        "#add_all_texts_to_collection()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
