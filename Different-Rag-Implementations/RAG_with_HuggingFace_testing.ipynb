{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym5dMYn-9Sum"
      },
      "source": [
        "## Hello, Here's How to use RAG w HF Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNlcwxKR9gXt"
      },
      "source": [
        "Install some dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0wlrXoS1EP-",
        "outputId": "66a965ad-b8ac-473d-a552-c78fd2799acc"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U peft==0.8.2\n",
        "!pip install -q -U trl==0.7.10\n",
        "!pip install -q -U accelerate==0.27.1\n",
        "!pip install -q -U datasets==2.17.0\n",
        "!pip install -q -U transformers==4.38.1\n",
        "!pip install langchain sentence-transformers chromadb langchainhub\n",
        "\n",
        "!pip install langchain-community langchain-core"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DedwIx35-UcR"
      },
      "source": [
        "Get the Model You Want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hu5dP1rbDv0E",
        "outputId": "934dafda-28f1-4851-cb18-0ecd9d07b7e8"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade --upgrade-strategy eager \"optimum[neural-compressor]\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgrfSeOhCriu",
        "outputId": "8d14b180-3ed2-4ef0-a90b-655bca22ce80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.11/dist-packages (0.18.0)\n"
          ]
        }
      ],
      "source": [
        "#!pip install fuzzywuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG8Dqg_6JcML",
        "outputId": "bc56b49a-217e-4008-904b-a12dfaab0791"
      },
      "outputs": [],
      "source": [
        "#!pip install optimum\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "M-dvCR_M1qQR"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "import chromadb\n",
        "\n",
        "import time\n",
        "import uuid\n",
        "#from fuzzywuzzy import fuzz\n",
        "#from optimum.quantization import QuantizeruenceClassification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBaYgY2WJEZF",
        "outputId": "21a14e6b-53e7-43b2-c3f9-db633b1d4bcc"
      },
      "outputs": [],
      "source": [
        "#pip install numpy --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaDCl4Jj-YCQ"
      },
      "source": [
        "Define Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymTffeGN4EH-",
        "outputId": "bb3e6fd3-e3c0-4b39-950f-a3172095129d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# set your own hf token then fetch it here\n",
        "hf_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "\n",
        "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, token=hf_token)\n",
        "\n",
        "model.half()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBA-ljP5-bOR"
      },
      "source": [
        "Define Data Sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UVLl-QTT61Aw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_names = [\n",
        "    \"study_permit_general\",\n",
        "    \"work_permit_student_general\",\n",
        "    \"work-and-education-data\",\n",
        "    \"vancouver_transit_qa_pairs\",\n",
        "    \"permanent_residence_student_general\",\n",
        "    \"data-with-sources\"\n",
        "]\n",
        "\n",
        "all_texts = []\n",
        "\n",
        "for file in file_names:\n",
        "    path = f'./sample_data/{file}.csv'\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        df.columns = df.columns.str.lower()\n",
        "\n",
        "        if 'question' in df.columns and 'answer' in df.columns:\n",
        "            df = df.drop_duplicates(subset=['question'])\n",
        "            df['text'] = df['question'].fillna('') + ' ' + df['answer'].fillna('')\n",
        "        elif 'theme' in df.columns and 'content' in df.columns:\n",
        "            df = df.drop_duplicates(subset=['content'])\n",
        "            df['text'] = df['theme'].fillna('') + ' ' + df['content'].fillna('')\n",
        "        else:\n",
        "            print(f\"no text columns in {file}\")\n",
        "            continue\n",
        "        all_texts.extend(df['text'].tolist())\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP8skJRg8LZ_",
        "outputId": "d7225af6-0281-478b-c20c-c3f6489393e4"
      },
      "outputs": [],
      "source": [
        "# forgot one dependency\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5NPcS-__W2F"
      },
      "source": [
        "Set Embedding Model, and Chroma Client to Interact w Vector Database and Create Collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCNO3e62K-G3",
        "outputId": "9b2271e0-cb60-4b5d-f972-758639f259de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.4)\n"
          ]
        }
      ],
      "source": [
        "#!pip install -U numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKdxYOca7KfJ",
        "outputId": "34564ef5-0260-4b54-c037-909ffc55f84b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successfully added 1053 documents to Chroma DB.\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "import chromadb\n",
        "import uuid\n",
        "import pandas as pd\n",
        "#from fuzzywuzzy import fuzz\n",
        "\n",
        "# pt model for geenrating embeddings used pretty often\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "# persistent client to interact w chroma vector store\n",
        "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "# create collections for each data (for testing rn)\n",
        "collection = client.get_or_create_collection(name=\"combined_docs\")\n",
        "\n",
        "# seems like better results if we remove duplicates and very similar data\n",
        "data = pd.DataFrame({\"text\": all_texts})\n",
        "data = data.drop_duplicates()\n",
        "all_texts = data[\"text\"].tolist()\n",
        "\n",
        "'''\n",
        "def remove_fuzzy_duplicates(texts, threshold=90):\n",
        "    unique_texts = []\n",
        "    for text in texts:\n",
        "        if not any(fuzz.ratio(text, existing_text) > threshold for existing_text in unique_texts):\n",
        "            unique_texts.append(text)\n",
        "    return unique_texts\n",
        "\n",
        "all_texts = remove_fuzzy_duplicates(all_texts, threshold=90)\n",
        "'''\n",
        "\n",
        "print(f\"successfully added {len(all_texts)} documents to Chroma DB.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOEGkLgl_e2Z"
      },
      "source": [
        "Function to add data to collection by embedding them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "9lN1Q5d_8jZt"
      },
      "outputs": [],
      "source": [
        "def add_data_to_collection_batch(collection, texts, batch_size=3):\n",
        "    for idx in range(0, len(texts), batch_size):\n",
        "        try:\n",
        "            batch_texts = texts[idx: idx + batch_size]\n",
        "\n",
        "            embeddings = embedding_model.embed_documents(batch_texts)\n",
        "\n",
        "            batch_ids = [str(uuid.uuid4()) for _ in batch_texts]\n",
        "\n",
        "            collection.add(\n",
        "                ids=batch_ids,\n",
        "                embeddings=embeddings,\n",
        "                documents=batch_texts\n",
        "            )\n",
        "            print(f\"successfully added {len(batch_texts)} documents (Batch {idx}-{idx + batch_size - 1})\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing batch starting at index {idx}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JEgUfbRMg5e",
        "outputId": "d844addb-edb2-4645-b912-f685ccd8dd45"
      },
      "outputs": [],
      "source": [
        "add_data_to_collection_batch(collection, all_texts)\n",
        "print(f\"successfully added {len(all_texts)} documents to the Chroma collection.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn2LQiJq_k9t"
      },
      "source": [
        "Function to now match for releveant document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TEulNQZw8mDo"
      },
      "outputs": [],
      "source": [
        "def get_relevant_documents(query, n_results=3):\n",
        "    try:\n",
        "        query_embeddings = embedding_model.embed_documents([query])[0]\n",
        "\n",
        "        results = collection.query(query_embeddings=[query_embeddings], n_results=n_results)\n",
        "        print(f\"Query Results: {results}\")\n",
        "\n",
        "        return results['documents'][0] if results['documents'] else []\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV_h8UJa_pGj"
      },
      "source": [
        "Generate Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "EMTYliNl8onj"
      },
      "outputs": [],
      "source": [
        "def generate_answer(query):\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\")\n",
        "    base_output = model.generate(inputs[\"input_ids\"], max_length=150, temperature=0.1)\n",
        "    response_before_rag = tokenizer.decode(base_output[0], skip_special_tokens=True)\n",
        "\n",
        "    relevant_documents = get_relevant_documents(query)\n",
        "    if not relevant_documents:\n",
        "        return {\n",
        "            \"Before RAG Response\": response_before_rag,\n",
        "            \"After RAG Response\": \"Sorry, no relevant documents found.\"\n",
        "        }\n",
        "\n",
        "    relevant_texts = \"\\n\\n\".join([doc for doc in relevant_documents])\n",
        "    rag_prompt = f\"\"\"\n",
        "    You are a helpful assistant for international students. Here are relevant documents:\n",
        "\n",
        "    {relevant_texts}\n",
        "\n",
        "    Please respond to the following question based on the documents above. Be conversational but concise:\n",
        "\n",
        "    Question: {query}\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    rag_inputs = tokenizer(rag_prompt, return_tensors=\"pt\")\n",
        "    rag_output = model.generate(rag_inputs[\"input_ids\"], max_length=500, temperature=0.1)\n",
        "    response_after_rag = tokenizer.decode(rag_output[0], skip_special_tokens=True)\n",
        "\n",
        "    return {\n",
        "        \"Before RAG Response\": response_before_rag,\n",
        "        \"After RAG Response\": response_after_rag\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxtEFTiK_q8E"
      },
      "source": [
        "Example Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EVDilNoM8sU8",
        "outputId": "7caa2fec-3bb2-4f84-9089-f1476855bc63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Results: {'ids': [['a9e9b5f4-01e3-469b-b7c1-768022665ff5', 'd8a7253f-3659-448c-bb0c-b8489df8af47', '30a5a828-0efc-428a-989f-836ffc0c6d06']], 'embeddings': None, 'documents': [['Study Permit Application Process When you apply online, your personalized checklist will include the Application to Change Conditions, Extend my Stay or Remain in Canada as a Student [IMM 5709]. On that form, check the box to Apply for a study permit for the first time or extend my study permit and fill out the rest of the required fields.', 'Study Permit Application Process Most foreign nationals already in Canada can no longer apply for a study permit at a port of entry. You must apply online for', 'Extending a Study Permit If you want to keep studying in Canada, you must']], 'uris': None, 'data': None, 'metadatas': [[None, None, None]], 'distances': [[0.3383488655090332, 0.40008115768432617, 0.40086132287979126]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Test Query 1: How do I apply for a study permit in Canada?\n",
            "==================================================\n",
            "Response Before RAG:\n",
            " How do I apply for a study permit in Canada? The application process typically involves several steps, which I'll outline below.\n",
            "\n",
            "## Step 1: Determine Your Eligibility\n",
            "To apply for a study permit in Canada, you must meet certain eligibility criteria. These include being a permanent resident of Canada, having a valid passport, and having sufficient funds to support yourself during your stay in Canada.\n",
            "\n",
            "## Step 2: Choose the Correct Application Type\n",
            "There are two main types of study permits: a study permit for a specific program (e.g., a bachelor's degree) and a study permit for a general program (e.g., a master's degree). You must choose the correct application type based on your program of study.\n",
            "\n",
            "## Step 3\n",
            "\n",
            "Response After RAG:\n",
            " \n",
            "    You are a helpful assistant for international students. Here are relevant documents:\n",
            "\n",
            "    Study Permit Application Process When you apply online, your personalized checklist will include the Application to Change Conditions, Extend my Stay or Remain in Canada as a Student [IMM 5709]. On that form, check the box to Apply for a study permit for the first time or extend my study permit and fill out the rest of the required fields.\n",
            "\n",
            "Study Permit Application Process Most foreign nationals already in Canada can no longer apply for a study permit at a port of entry. You must apply online for\n",
            "\n",
            "Extending a Study Permit If you want to keep studying in Canada, you must\n",
            "\n",
            "    Please respond to the following question based on the documents above. Be conversational but concise:\n",
            "\n",
            "    Question: How do I apply for a study permit in Canada?\n",
            "\n",
            "    Answer:\n",
            "     To apply for a study permit in Canada, you can apply online through the Immigration, Refugees and Citizenship Canada (IRCC) website. You will need to provide personal and educational information, as well as proof of financial support and health insurance. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial support and health insurance, as well as a copy of your passport. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial support and health insurance, as well as a copy of your passport. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial support and health insurance, as well as a copy of your passport. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial support and health insurance, as well as a copy of your passport. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial support and health insurance, as well as a copy of your passport. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial support and health insurance, as well as a copy of your passport. You can also apply for a study permit at a port of entry if you are already in Canada. You will need to provide proof of financial\n",
            "==================================================\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Results: {'ids': [['f49f0ece-d747-4594-a770-721355511f00', '0e1017e4-90c6-49d3-be3a-7a9428aeeafb', '22006685-c985-4364-8d8d-8e6d8268c1fb']], 'embeddings': None, 'documents': [[\"Work Permits for International Students If you're able to work during your studies, it'll say so in the conditions on your study permit.\", \"Work Permits for International Students If you're able to work during your studies, it'll say so in the conditions on your study permit.\", \"Work Permits for International Students If you're able to work during your studies, it'll say so in the conditions on your study permit.\"]], 'uris': None, 'data': None, 'metadatas': [[None, None, None]], 'distances': [[0.5540599822998047, 0.5540599822998047, 0.554060161113739]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Test Query 2: Can I work while studying on a student visa?\n",
            "==================================================\n",
            "Response Before RAG:\n",
            " Can I work while studying on a student visa? Working while studying on a student visa is a common practice, but it's essential to understand the rules and regulations surrounding it.\n",
            "\n",
            "**Understanding the rules:**\n",
            "\n",
            "*   **Employment and student status:** You must be a student and not an employee to work while studying on a student visa.\n",
            "*   **Work hours and duration:** You can work up to 20 hours per week, and you must not exceed 40 hours per month.\n",
            "*   **Employment contract:** You must have a written employment contract with your employer, which includes the terms of your employment, working hours, and salary.\n",
            "*   **Tax and benefits:** You must pay taxes on your earnings and benefits, and you\n",
            "\n",
            "Response After RAG:\n",
            " \n",
            "    You are a helpful assistant for international students. Here are relevant documents:\n",
            "\n",
            "    Work Permits for International Students If you're able to work during your studies, it'll say so in the conditions on your study permit.\n",
            "\n",
            "Work Permits for International Students If you're able to work during your studies, it'll say so in the conditions on your study permit.\n",
            "\n",
            "Work Permits for International Students If you're able to work during your studies, it'll say so in the conditions on your study permit.\n",
            "\n",
            "    Please respond to the following question based on the documents above. Be conversational but concise:\n",
            "\n",
            "    Question: Can I work while studying on a student visa?\n",
            "\n",
            "    Answer:\n",
            "     Yes, you can work while studying on a student visa. In fact, many students on a student visa are able to work part-time to support themselves financially. However, you'll need to check the specific conditions on your study permit to see if you're eligible to work. Some student visas, like the F-1 visa, have specific requirements for work permits, while others, like the J-1 visa, have different rules. It's always a good idea to check with the relevant authorities or your university to confirm your eligibility.\n",
            "==================================================\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Results: {'ids': [['13b81354-0ec4-4fda-a068-7d9496a1ee48', '267bbdd2-8c18-4878-af02-bb4069d92172', 'c6082afc-c3b5-466e-9ce1-02a40b1b3e29']], 'embeddings': None, 'documents': [['Study Permit Expiration and Renewal What happens when your permit expires\\nYou lose your student status in Canada if any of the following applies to you:', 'Extending a Study Permit What happens when your permit expires\\nYou lose your student status in Canada if any of the following applies to you:', 'Extending a Study Permit What happens when your permit expires\\nYou lose your student status in Canada if any of the following applies to you:']], 'uris': None, 'data': None, 'metadatas': [[None, None, None]], 'distances': [[0.38881877064704895, 0.43466609716415405, 0.43466609716415405]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Test Query 3: What happens if my study permit expires before I finish my program?\n",
            "==================================================\n",
            "Response Before RAG:\n",
            " What happens if my study permit expires before I finish my program? Can I still enter Canada?\n",
            "If your study permit expires before you finish your program, you may be eligible to apply for a new study permit. However, there are some conditions and requirements you need to meet.\n",
            "\n",
            "Here are the steps to follow:\n",
            "\n",
            "1. **Check if your study permit has expired**: You can check the status of your study permit online through the Immigration, Refugees and Citizenship Canada (IRCC) website.\n",
            "2. **Contact the IRCC**: If your study permit has expired, contact the IRCC to inquire about the next steps. They may ask you to provide documentation, such as proof of payment for the application fee or proof of completion of your program.\n",
            "\n",
            "\n",
            "Response After RAG:\n",
            " \n",
            "    You are a helpful assistant for international students. Here are relevant documents:\n",
            "\n",
            "    Study Permit Expiration and Renewal What happens when your permit expires\n",
            "You lose your student status in Canada if any of the following applies to you:\n",
            "\n",
            "Extending a Study Permit What happens when your permit expires\n",
            "You lose your student status in Canada if any of the following applies to you:\n",
            "\n",
            "Extending a Study Permit What happens when your permit expires\n",
            "You lose your student status in Canada if any of the following applies to you:\n",
            "\n",
            "    Please respond to the following question based on the documents above. Be conversational but concise:\n",
            "\n",
            "    Question: What happens if my study permit expires before I finish my program?\n",
            "\n",
            "    Answer:\n",
            "     If your study permit expires before you finish your program, you will lose your student status in Canada. This means you will no longer be eligible to study in Canada and will need to apply for a new study permit. You may also need to apply for a work permit if you want to work in Canada.\n",
            "==================================================\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Results: {'ids': [['b93fb3dc-8910-4cbb-858b-39291370569c', '8a55474b-3669-47fb-920d-6e8d4fa73cf6', 'c6ac72f1-0967-458d-80f5-547120bf2138']], 'embeddings': None, 'documents': [[\"Extending a Study Permit If your study situation changes\\nIf you weren't eligible to work off campus, but your study situation has now changed, you may be able to change the conditions of your study permit.\", \"Study Permit Application Process If your study situation changes\\nIf you weren't eligible to work off campus, but your study situation has now changed, you may be able to change the conditions of your study permit.\", 'Extending a Study Permit keep studying until your current permit expires or\\ntransfer to another DLI\\nIf you want to extend your study permit, you’ll need to enroll at a school with DLI status.']], 'uris': None, 'data': None, 'metadatas': [[None, None, None]], 'distances': [[0.6665720343589783, 0.6875311136245728, 0.7013002634048462]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-4019d776cd8e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_query\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-1013fe83b582>\u001b[0m in \u001b[0;36mgenerate_answer\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mrag_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrag_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mrag_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrag_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mresponse_after_rag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrag_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2048\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynced_gpus\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    998\u001b[0m                 )\n\u001b[1;32m    999\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1001\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "test_queries = [\n",
        "    \"How do I apply for a study permit in Canada?\",\n",
        "    \"Can I work while studying on a student visa?\",\n",
        "    \"What happens if my study permit expires before I finish my program?\",\n",
        "    \"Do I need a new study permit if I change schools?\",\n",
        "    \"How long does it take to process a Canadian study permit?\",\n",
        "    \"Am I allowed to work off-campus as an international student?\",\n",
        "    \"How many hours can I work while studying in Canada?\",\n",
        "    \"What documents do I need to apply for a co-op work permit?\",\n",
        "    \"Can I work in Canada after I graduate?\",\n",
        "    \"What is a Post-Graduation Work Permit (PGWP) and how do I apply?\",\n",
        "    \"How do I apply for MSP (Medical Services Plan) in British Columbia?\",\n",
        "    \"Is MSP mandatory for international students?\",\n",
        "    \"What healthcare services are covered under MSP?\",\n",
        "    \"What should I do if I get sick and don’t have insurance yet?\",\n",
        "    \"Can I use private health insurance instead of MSP?\",\n",
        "    \"What are my options for student housing in Vancouver?\",\n",
        "    \"How much does rent typically cost for international students?\",\n",
        "    \"What should I check before signing a lease in Canada?\",\n",
        "    \"Are there any student discounts for accommodation?\",\n",
        "    \"How can I find a roommate in Canada?\",\n",
        "    \"How do I open a bank account as an international student?\",\n",
        "    \"What documents do I need to get a student bank account?\",\n",
        "    \"Can I get a credit card as an international student?\",\n",
        "    \"How do I send money to my home country from Canada?\",\n",
        "    \"What scholarships are available for international students?\",\n",
        "    \"How does the Compass Card work for transit in Vancouver?\",\n",
        "    \"Am I eligible for a U-Pass as an international student?\",\n",
        "    \"What is the best way to get around Vancouver on a budget?\",\n",
        "    \"Where can I find the bus and SkyTrain schedules?\",\n",
        "    \"Are there student discounts for public transportation?\",\n",
        "    \"Can I apply for permanent residence after graduating?\",\n",
        "    \"What is the Canadian Experience Class (CEC) immigration program?\",\n",
        "    \"How can I improve my chances of getting permanent residence?\",\n",
        "    \"What are the eligibility requirements for Express Entry?\",\n",
        "    \"Does having a Canadian degree help with PR applications?\"\n",
        "]\n",
        "\n",
        "for idx, user_query in enumerate(test_queries, start=1):\n",
        "    responses = generate_answer(user_query)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Test Query {idx}: {user_query}\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Response Before RAG:\\n\", responses[\"Before RAG Response\"])\n",
        "    print(\"\\nResponse After RAG:\\n\", responses[\"After RAG Response\"])\n",
        "    print(\"=\"*50 + \"\\n\\n\")\n",
        "\n",
        "#add_all_texts_to_collection()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "CampusConnect",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
